# 22\.11.2023 - Band III, ENDE
Anerkennung – Wertschätzung – Zugehörigkeit (Grundbedürfnisse des Menschen)


PoR:: Plan of Record

DAK:: Daimler-Auslegungs-Kollektiv

Umweltsimulationstests: PTCE:: HTOE (High Temperature Operation Endurance) and PTCE (Power Thermal Cycle Endurance) and Thermoschocktest

Betriebsfestigkeit à Metallurgische Kerbe; Geometrische Kerbe

Eigenfrequenzen à Resonanzkatastrophe!!! à Dämpfung und oder Masse (Verschieben der Eigenfrequenzen)

Bullshit-Bingo: “Neckbreaker“

Freaky Verfahren: z.B. Autofrettage

Industrie 4.o à siehe ChatGPT

Kanban-Tafel (Todo, doing, done)

Burn-Down-Chart à siehe ChatGPT

Anders’ Diagramm zur Zusammenarbeit:

1. Surface Acting
1. Performed Authenticity
1. FIREWALL
1. The Core (Me, Myselft & I)
1. The Bios
# Produktentwicklung
PRODUKTIONSTECHNIK?

PRODUKTIONSPLANUNG?

Vision; Attraktives Zukunftsbild; Pitchen von Ideen, Förderer finden.

Blue-Sky-Concept; Blue-Sky-(Design)-Thinking

So there’s a term that some designers may know, but most designers probably won’t unless you’re doing new product development that will leverage all of our current and near future technology. That term is “Blue Sky (Design) Thinking” which simply means to do the most creative thinking you possibly can that is not conventional and not grounded in today’s reality. By doing this means you really think outside the box to problem solve challenges and then once you’ve vetted out your creative ideas, it’s time to reel it in some to see what we can actually do now or in the near term. One of the benefits of doing projects like this is to break your design normal pattern, go out into the world to create inspiration boards of current competitor products, new technology products, and see what various different ways of current products out there that you can bring bits and pieces of to solve the current challenges that you have today. This also helps you push your design skills as well as to push the skills of your development team as well. The ultimate goal of Blue Sky Thinking to take what you currently may have and push your product or service into the future for a better user experience for current and new customers that you may have.

Organisation: z.B. Vorentwicklung – Serienentwicklung – Produktionsplanung – Produktion

*“The most dangerous phrase in the language is, ‘We’ve always done it this way.’*” [Grace Hopper] 

Eigeninitiative (innerhalb der Regeln) ist (bis auf wenige Ausnahmen) immer gut.

Bauteilverantwortliche, Teilprojektleiter, Arbeitspaketleiter,

Kosten/Zielvorgaben, Zeitleiste, Meilensteine à Controlling einbinden!

Zielhierarchie, Umgang mit widersprechenden Zielvorgaben (Anwendbar auf Produktentwicklung; Konzept ist jedoch Universell, u.a. auch Personalführung). Bsp: Asimov‘s Robotergesetze.

- Exkurs: Woher stammen Ziele, wie werden Zielvorgaben ermittelt (insb. bei neuen Produkten ohne direkte Vorgänger, Beispiel Landemanöver Perseverence à Zusätzliche Sensoren zum Sammeln von Wissen für folgende Missionen).

Randbedingungen und Annahmen, unter denen Ziele gelten, den Zielen zugestimmt wurde, dokumentieren

- Exkurs: Topologie von Bauteilen. Wo liegt die Verantwortung für welche Komponente des Produkts, z.B. Grenze von Motor und Getriebe „Das Ölschaufelrad ist ein Getriebeteil“, z.B. Grenze von Mechanik, Elektrik und Software bei mechatronischen Systemen.)
> *„Wir müssen die Lücke schließen, haben aber noch keinen Zielwert.“*
>
> *„Kostenwalk“*

Steckbriefe („Steckbrieferstellungsworkshop“); z.B. Projektsteckbrief (Kurzbeschreibung, was in dem Projekt gemacht werden soll, welche Aufwände und Zeit benötigt wird, usw.).

Überführen von Zielen (z.B. Gewichtsziel Äquivalent in Kosten z.B. 1kg = 20€)

Oder auch 1% Wirkungsgrad = 40€ Herstellkosten (bei E-Motoren).

Herkunft der Vorgaben klären und verstehen

Randbedingungen bei Produktentwicklung, u.a. Temperatur, Temperaturwechsel, Medien, Druck, Vibration, Veränderungen der Randbedingungen u.a. wg. Alterung, Abrieb, usw.)

„Wann ist das Ziel erreicht? Wann ist das Projekt erfolgreich beendet?“

Möglichst konkrete Ziele definieren und festschreiben; „Moving Targets“ vermeiden!

Controlling: 
> *„If you can’t measure it, you can’t manage it.“*
>
> *„Kostenarbeit“*

Verbindlichkeit, Transparenz: Für alle Beteiligte Protokollierung und Archivierung à Projektmanagement. („Listenschubser“).

## SIMULATIONSRICHTILINIE
Richtlinie mit Vorgaben, um Simulationen kompatibel und die Ergebnisse nachvollziehaber und vergleichbar zu machen. Enthält neben technischen Aspekten auch organisatorische Aspekte, z.B. zu welchen Zeitpunkten welche Datenqualität erreicht sein muss (àDigitale Prozesstage, vergleichbar realer Abnahmetermine)

Thermal Shock – Corrosion- Oil – High Temperatur – Humidity – Temperatur Cycle 

Six-sigma: CTQ (Critical to Quality)

**Quality-Gates: Prinziptauglichkeit à Konzepttauglichkeit à Serientauglichkeit**

- Erprobungswürdig ; Konzeptvergleich

In der Vorlesung unbedingt auf die zeitliche Verschränkung eingehen. Da bei anspruchsvollen Zeitleisten in der Regel kein Plan B verfügbar ist muss die Konzepttauglichkeit eigentlich schon vorhanden sein bevor man den Nachweis der Konzepttauglichkeit startet!! Gerade die Prozessentwicklung muss eigentlich mindestens ein Qualitygate vorauseilen!

Technologieradar à Absicherungslandkarte à Fehlerabstellprozess

Test, Testbarkeit 

(Hardware, aber ebenso Software à Automatisierte Tests, bei Software ggf. vollständiger Test).

- Exkurs: Testbarkeit von KI?

Lebensdauertest

Softwareentwicklung (20…30% Progammieraufand, 40% Projektorganisation und Dokumentation, 30% Testaufwand) (Quelle F. Aichele, mündliche Mitteilung).

Use-Cases

Prüfrichtlinie

Fertigungstiefe

Produktionsprozesse und deren Abfolgen

Bewertungsmarix; Morphologischer Kasten; Kompatibilitätsmatrix

Fachexperten einbinden; bestmögliche Lösung ermitteln, Entscheidungsfindung dokumentieren. 
> *„Not invented here.“*
>
> *„Hinmoderieren.“ à In der Rolle des Moderators gewünschte Ergebnisse durch gezieltes Eingreifen erreichen.*
>
> *„Surface acting“*
>
> *„Don’t tell me, show me.“*

- Exkurs: Team, Teambuilding, Soft-Skills (z.B. Feedbackkultur), Hidden-Agenda.
> *„Team: Toll, ein anderer macht’s.“*

- Exkurs: Matrixorganisation (System wechselseitiger Abhängigkeit und gemeinsamer Verantwortung).

Demonstrator
> *„Wir iterieren uns vor.“*

Aufbauplanung Muster

Handlungsfeld Logistik: u.a. Anlieferung|Abholung|Menge|Risiko/Status

Transparente Dokumentation und Verfolgung von Aufgaben (Open-Point-List inkl. Status, Verantwortliche\*m, nächste Schritte, Datum).

Kunde und Verwendungszweck

# Prozessentwicklung

![](Aspose.Words.e14cf7f3-6a3e-4150-b56e-2ba738c551dd.001.png)

**Abb.:** Produktionssystem-Entwicklung (Quelle: W. Polley)

Toleranzen, Toleranzmanagement (CAD vs. Realität), z.B. Pouch-Zellen, Elektroblechpakete

Qualitätsmanagement

*Aufgabe: Themenfeld Betriebsfestigkeit: Vorwissen der Studierenden?*

- Exkurs: Woher ist der schlimmstmögliche Lastfall bekannt? (Bsp.: Schwingfestigkeit (à Lastkollektiv, Wöhlerlinien, Betriebsfestigkeit (oder auch Zeitfestigkeit) vs. Dauerfestigkeit); Lineare Schadensakkumulation (Palmgren-Miner-Regel); Schleudertest vs. Betriebsfestigkeit bei Elektromotoren). Für welche Lastkollektive wird ausgelegt („5%-Fahrer“)? 

Ausschreibung – Vergabe – Versandabnahme – Abnahme. 

Hochvolt-Sicherheit: Isolationswiderstand + Stehspannungsprüfung + Stoßspannungsprüfung.

Beispiel für Fertigungstechnik. NdFeB-Magnete. China: Hoher Anteil Neodym (Nd relativ günstig), Japan: Super-Grain-Boundary-Diffusion-Process (bessere Terbium-Diffusion Fa. Shin-Etsu) (Schwere-Seltene-Erden-reduzierte Magnete teuer, ABER hohe Prozesskompetenz): Ergebnis: Gleiche thermische Eigenschaften der Magnete und gleicher Preis, aber unterschiedliche Verteilung von Herstell- und Materialkosten.
# Produktionsplanung
> *„Plan of Record (PoR)“* 

A Plan of Record (PoR) is a simple, yet powerful document that is easy to read and sets clear expectations for a given period of time.

DIN8580 Fertigungsverfahren (1. Urformen, 2. Umformen, 3. Trennen, 4. Fügen, 5. Beschichten, 6. Stoffeigenschaften ändern) 

Stichworte: Kritischer Pfad; Meilensteine; „Rote Laterne“
## Wertorientierte Produktion
"Wertorientierte Produktion" ist ein Konzept im Bereich des Produktionsmanagements und der Unternehmensführung, das darauf abzielt, den Fokus von der reinen Produktionsmenge hin zur Schaffung von Wert für Kunden, Mitarbeiter und das Unternehmen insgesamt zu lenken. Es geht darum, Produktion nicht nur als reine Herstellung von Produkten zu betrachten, sondern als einen Prozess, der auf die Maximierung des Wertbeitrags ausgerichtet ist.

Hier sind einige Kernaspekte und Informationen im Zusammenhang mit wertorientierter Produktion:

1\. \*\*Kundenzentrierung\*\*: Wertorientierte Produktion legt großen Wert darauf, die Bedürfnisse und Anforderungen der Kunden zu verstehen und zu erfüllen. Produkte und Dienstleistungen werden so gestaltet und produziert, dass sie einen hohen Wert für die Kunden bieten.

2\. \*\*Wertschöpfung\*\*: Das Konzept betont die Optimierung der Wertschöpfung entlang der gesamten Wertschöpfungskette. Dies beinhaltet die Identifizierung und Beseitigung von Verschwendung, um effizientere und kosteneffektive Prozesse zu schaffen.

3\. \*\*Qualität und Exzellenz\*\*: Wertorientierte Produktion legt großen Wert auf die Qualität von Produkten und Dienstleistungen. Durch die Fokussierung auf Qualität wird nicht nur die Kundenzufriedenheit erhöht, sondern auch die betriebliche Effizienz gesteigert.

4\. \*\*Messbare Ergebnisse\*\*: In einer wertorientierten Produktion werden Leistungskennzahlen verwendet, um den Wertbeitrag zu messen und zu überwachen. Dies ermöglicht eine kontinuierliche Verbesserung und Anpassung der Produktion, um den Mehrwert zu maximieren.

5\. \*\*Nachhaltigkeit\*\*: Wertorientierte Produktion berücksichtigt oft auch ökologische und soziale Aspekte. Dies schließt die Verantwortung für die Umwelt, die Einhaltung von ethischen Standards und die Schaffung eines gesunden Arbeitsumfelds ein.

6\. \*\*Agilität und Anpassungsfähigkeit\*\*: In einer sich ständig verändernden Geschäftswelt ist es wichtig, flexibel und anpassungsfähig zu sein. Wertorientierte Produktion fördert die Agilität und die Fähigkeit, schnell auf Veränderungen zu reagieren.

7\. \*\*Unternehmenskultur\*\*: Das Konzept der wertorientierten Produktion geht oft mit einer spezifischen Unternehmenskultur einher, die auf Wertschätzung, Teamarbeit, kontinuierlicher Verbesserung und Innovationsbereitschaft basiert.

8\. \*\*Strategische Ausrichtung\*\*: Wertorientierte Produktion ist oft eng mit der Unternehmensstrategie verbunden. Die Produktionsprozesse werden darauf ausgerichtet, die strategischen Ziele des Unternehmens zu unterstützen.

Insgesamt zielt die wertorientierte Produktion darauf ab, die Produktion in eine wertschaffende Aktivität zu verwandeln, die nicht nur auf Effizienz, sondern auch auf die Schaffung von Mehrwert für Kunden, Mitarbeiter und das Unternehmen selbst abzielt.


Übergabetestat „Readiness Manufacturing“.

Instandhaltung; Predictive Maintenance

Planung erstellt Lastenheft für Produktionsanlagen, Nicht Produktentwicklung, Nicht Verfahrensentwicklung. à Klare Zuständigkeiten sind entscheidend!

# Arbeitsorganisation
Aufgaben – Kompetenz – Verantwortung 

Key-Account („Single-face to the customer“); auch z.B. Gewerke-Key-Account

Leistungsverlust 0,3…0,5 Prozent/Jahr ab dem 30. Lebensjahr.



## SIMULATION IN DER PRODUKTIONSPLANUNG
In der Produktionsplanung werden verschiedene Simulationswerkzeuge eingesetzt, um komplexe Prozesse zu analysieren, zu optimieren und Entscheidungen zu unterstützen. Diese Werkzeuge ermöglichen es, verschiedene Szenarien virtuell zu modellieren und deren Auswirkungen auf die Produktionsprozesse zu bewerten. Hier sind einige der häufig verwendeten Simulationswerkzeuge in der Produktionsplanung:

1\. \*\*Diskrete-Event-Simulation (DES)\*\*: DES ist eine weit verbreitete Simulationsmethode, bei der der Produktionsprozess in diskrete Ereignisse zerlegt wird. Es modelliert den Fluss von Einheiten (z. B. Produkte) durch verschiedene Stationen und analysiert, wie Ereignisse in der Zeit ablaufen. DES kann zur Optimierung von Produktionslinien, Lagerbeständen und Ressourcennutzung verwendet werden.

2\. \*\*Monte-Carlo-Simulation\*\*: Diese Methode nutzt Zufallszahlen, um verschiedene Parameter und Einflussfaktoren zu modellieren. Sie ermöglicht die Analyse von Unsicherheiten und Risiken in der Produktionsplanung und hilft dabei, Wahrscheinlichkeitsverteilungen von Ergebnissen zu bestimmen.

3\. \*\*Systemdynamik-Simulation\*\*: Systemdynamikmodelle fokussieren sich auf die langfristigen Veränderungen und Rückkopplungseffekte in komplexen Systemen. Sie können in der Produktionsplanung verwendet werden, um die Auswirkungen von strategischen Entscheidungen auf lange Sicht zu bewerten.

4\. \*\*Agentenbasierte Simulation\*\*: In dieser Methode werden individuelle Agenten (z. B. Maschinen, Mitarbeiter) modelliert, die autonom agieren und miteinander interagieren. Agentenbasierte Simulationen können genutzt werden, um das Verhalten und die Dynamik von Systemen mit vielen Interaktionen zu analysieren.

5\. \*\*Arena\*\*: Arena ist eine kommerzielle Simulationssoftware, die auf diskreter Ereignissimulation basiert. Sie wird häufig für die Modellierung und Analyse von Produktions- und Logistikprozessen eingesetzt.

6\. \*\*AnyLogic\*\*: AnyLogic ist eine vielseitige Simulationsplattform, die verschiedene Simulationsmethoden unterstützt, darunter diskrete Ereignissimulation, Agentenbasierte Simulation und Systemdynamik. Sie kann für eine breite Palette von Anwendungen in der Produktionsplanung genutzt werden.

7\. \*\*SIMUL8\*\*: SIMUL8 ist eine Simulationssoftware, die speziell auf diskrete Ereignissimulation ausgerichtet ist. Sie ermöglicht die Modellierung und Analyse von Prozessen in der Produktion, Logistik und anderen Bereichen.

8\. \*\*ProModel\*\*: ProModel ist eine weitere Simulationssoftware für diskrete Ereignissimulation, die für die Analyse und Optimierung von Produktionsprozessen verwendet wird.

Diese Simulationswerkzeuge unterstützen Produktionsplaner und Ingenieure dabei, verschiedene Szenarien zu testen, Engpässe zu identifizieren, Ressourcen optimal zuzuweisen und Risiken zu bewerten, bevor sie in der realen Produktion implementiert werden. Die Wahl des geeigneten Simulationswerkzeugs hängt von den spezifischen Anforderungen, der Komplexität des Systems und den verfügbaren Ressourcen ab.
## MONTE-CARLO-SIMULATION
Die Monte-Carlo-Simulation ist eine statistische Methode, die dazu dient, Unsicherheiten und Risiken in einem System zu analysieren, indem Zufallszahlen verwendet werden, um verschiedene Szenarien zu modellieren. Diese Methode basiert auf der Wiederholung von Zufallsexperimenten, um statistische Ergebnisse zu generieren, die Aufschluss über die Wahrscheinlichkeitsverteilung von Ergebnissen geben. Die Monte-Carlo-Simulation ist in vielen Bereichen der Wissenschaft, Ingenieurwissenschaften, Wirtschaft und anderen Disziplinen weit verbreitet.

Die wesentlichen Merkmale der Monte-Carlo-Simulation sind:

1\. \*\*Zufällige Variationen\*\*: Die Monte-Carlo-Simulation verwendet Zufallszahlen, um die Variationen und Unsicherheiten in einem System zu modellieren. Diese Zufallszahlen werden aus einer bestimmten Verteilung (z. B. Normalverteilung) generiert, die auf den verfügbaren Daten oder Annahmen basiert.

2\. \*\*Wiederholte Durchführung\*\*: Die Simulation wird mehrmals wiederholt, typischerweise Tausende oder Millionen von Malen. Bei jeder Wiederholung werden die Eingangsparameter (z. B. Kosten, Zeiten, Nachfrage) zufällig aus den angegebenen Verteilungen gezogen, um verschiedene Szenarien zu simulieren.

3\. \*\*Auswertung von Ergebnissen\*\*: Nach Abschluss der Simulation werden die generierten Ergebnisse analysiert. Dies können verschiedene Kennzahlen, Statistiken oder Wahrscheinlichkeitsverteilungen sein, die Aufschluss über die Leistung des Systems geben.

4\. \*\*Wahrscheinlichkeitsverteilungen\*\*: Die Monte-Carlo-Simulation verwendet Wahrscheinlichkeitsverteilungen, um die Unsicherheiten in den Eingangsparametern widerzuspiegeln. Diese Verteilungen können auf historischen Daten oder Annahmen basieren.

5\. \*\*Risikoanalyse\*\*: Die Methode ermöglicht es, Risiken und Wahrscheinlichkeiten verschiedener Ergebnisse zu bewerten. Dies hilft, potenzielle Risiken und Engpässe in einem System zu identifizieren.

6\. \*\*Flexibilität und Komplexität\*\*: Die Monte-Carlo-Simulation kann für komplexe Systeme angewendet werden, bei denen die Wechselwirkungen zwischen verschiedenen Variablen berücksichtigt werden müssen. Sie kann in verschiedenen Bereichen verwendet werden, darunter Finanzwesen, Ingenieurwissenschaften, Projektmanagement und mehr.

7\. \*\*Szenarienbewertung\*\*: Durch die Simulation verschiedener Szenarien können Entscheidungsträger besser verstehen, wie sich Änderungen in den Eingangsparametern auf die Ergebnisse auswirken könnten. Dies ermöglicht eine fundiertere Entscheidungsfindung.

Die Monte-Carlo-Simulation kann in der Produktionsplanung dazu verwendet werden, die Auswirkungen von Unsicherheiten in Faktoren wie Produktionszeiten, Ressourcenverfügbarkeit, Nachfragevariationen und anderen Parametern zu bewerten. Dies hilft bei der Identifizierung von Engpässen, der Ermittlung von Wahrscheinlichkeitsverteilungen von Ergebnissen und der Bewertung von Risiken, was letztlich zu besser informierten Entscheidungen führt.
### ANWENDUNGEN VON MONTE-CARLO-SIMULATION
Die Monte-Carlo-Simulation wird in verschiedenen Bereichen eingesetzt, um unsichere oder komplexe Probleme zu analysieren:

1\. \*\*Finanzwesen und Risikoanalyse\*\*: Die Monte-Carlo-Simulation wird häufig im Finanzwesen eingesetzt, um Risiken zu bewerten. Beispielsweise kann sie verwendet werden, um die zukünftige Performance von Investitionen zu simulieren und die möglichen Auswirkungen von Marktschwankungen auf den Portfolio-Wert zu analysieren. Durch die Modellierung verschiedener Szenarien und die Berücksichtigung von Unsicherheiten bei Renditen, Zinssätzen und anderen Faktoren kann die Simulation Investoren dabei unterstützen, fundierte Entscheidungen zu treffen.

2\. \*\*Ingenieurwissenschaften und Produktentwicklung\*\*: In der Produktentwicklung können Monte-Carlo-Simulationen verwendet werden, um die Auswirkungen von Unsicherheiten auf Produktleistung, Haltbarkeit oder andere technische Eigenschaften zu analysieren. Zum Beispiel könnte eine Simulation verwendet werden, um die Lebensdauer eines mechanischen Bauteils unter verschiedenen Belastungsbedingungen zu bewerten. Durch die Berücksichtigung von Variabilität in Materialfestigkeiten, Umgebungsbedingungen und Betriebsbedingungen kann die Simulation aufzeigen, wie wahrscheinlich das Bauteil in bestimmten Zeiträumen versagt.

3\. \*\*Logistik und Lieferkettenmanagement\*\*: Monte-Carlo-Simulationen können in der Logistik eingesetzt werden, um die Auswirkungen von Unsicherheiten in der Lieferkette zu analysieren. Zum Beispiel könnte eine Simulation verwendet werden, um die Lieferzeiten von verschiedenen Lieferanten zu modellieren und zu sehen, wie sich Verzögerungen auf den gesamten Produktionsablauf auswirken würden. Dies ermöglicht es Unternehmen, Pläne zur Risikominderung zu entwickeln, wie z.B. die Identifizierung von alternativen Lieferanten oder das Anlegen von Pufferbeständen.

### ROBUSTHEIT VON SYSTEMEN
Die Robustheit eines Systems bezieht sich auf seine Fähigkeit, stabil und zuverlässig zu funktionieren, selbst wenn es mit Störungen, Unsicherheiten oder variablen Bedingungen konfrontiert wird. Ein robustes System kann Schwankungen und Veränderungen in seinen Eingangsparametern oder Betriebsbedingungen tolerieren, ohne dass dies zu starken Beeinträchtigungen seiner Leistung führt. Robuste Systeme sind widerstandsfähig gegenüber Störungen und können sich an unvorhergesehene Situationen anpassen, ohne dass die Gesamtfunktionalität stark beeinträchtigt wird.

Die Robustheit eines Systems kann auf verschiedene Arten ermittelt oder eingeschätzt werden:

1\. \*\*Szenarienanalyse\*\*: Untersuchung verschiedener Szenarien, die das System herausfordern könnten. Durch die Modellierung von Worst-Case-Szenarien oder das Durchspielen von verschiedenen Störungen oder Änderungen können Schwachstellen identifiziert und die Auswirkungen auf das System bewertet werden.

2\. \*\*Sensitivitätsanalyse\*\*: Durch Variation der Eingangsparameter kann ermittelt werden, wie stark die Ergebnisse des Systems auf Änderungen reagieren. Dies hilft dabei, diejenigen Parameter zu identifizieren, die den größten Einfluss auf die Robustheit haben.

3\. \*\*Monte-Carlo-Simulation\*\*: Wie bereits erwähnt, kann die Monte-Carlo-Simulation verwendet werden, um die Auswirkungen von Unsicherheiten und Variationen in den Eingangsparametern auf das System zu analysieren. Durch die Analyse von Wahrscheinlichkeitsverteilungen von Ergebnissen können Bereiche ermittelt werden, in denen das System besonders empfindlich oder widerstandsfähig ist.

4\. \*\*Pufferkapazitäten\*\*: Das Einbeziehen von Pufferkapazitäten oder Pufferzeiten in die Planung und Ausführung eines Systems kann seine Fähigkeit zur Bewältigung von Schwankungen erhöhen. Dies kann bedeuten, zusätzliche Ressourcen oder Zeitreserven einzuplanen, um auf unerwartete Ereignisse reagieren zu können.

5\. \*\*Risikobewertung\*\*: Die Identifizierung und Bewertung potenzieller Risiken im Zusammenhang mit dem System kann dazu beitragen, mögliche Störungen frühzeitig zu erkennen und Maßnahmen zur Minimierung ihrer Auswirkungen zu ergreifen.

6\. \*\*Simulation und Testumgebungen\*\*: Durch die Verwendung von Simulationen oder Testumgebungen kann die Reaktion des Systems auf verschiedene Bedingungen überprüft werden, ohne dass reale Ressourcen gefährdet werden.

7\. \*\*Erfahrungswerte\*\*: Oft können Erfahrungen aus der Vergangenheit oder von ähnlichen Systemen Hinweise darauf geben, wie gut das System mit Störungen umgehen kann. Dies kann in Form von Fallstudien, Best Practices oder Fachwissen erfolgen.

Es ist wichtig zu betonen, dass die Robustheit nicht absolut ist und von vielen Faktoren abhängt, einschließlich der Art des Systems, der Umgebung, in der es betrieben wird, der Art der Störungen und der Fähigkeit zur Anpassung. Eine umfassende Analyse und die Berücksichtigung verschiedener Ansätze können dazu beitragen, die Robustheit eines Systems zu verbessern und seine Fähigkeit zur Bewältigung von Unsicherheiten zu stärken.


## ROBOTERSIMULATION

## NC-SIMULATION

## VIRTUELLE INBETRIEBNAHME

## MATERIALFLUSSSIMULATION

# Grundlagen
Fertigungsverfahren DIN8850


# PRETTY WORDS
„Wissen ist wahre, gerechtfertigte Überzeugung.“

„A big mistake is to design your business around what people say rather than what people buy!”

“Compliments don’t pay bills.”

„Kein Backup – Kein Mitleid!“

„Oft speichern rettet Leben.“

„Lots of copies keep stuff safe!”

FTE=Full Time Equivalent (Berechnung der Kapazität bei Beschäftigungsverhältnissen)

„What is said in the car stays in the car.” (Regel zum Gespräch auf Dienstreisen)

Mission==Was, Vision==Wohin, Purpose==Warum.

“Machen ist wie wollen, nur krasser!“ (Prof. Dr. Mario Roßdeutscher)

“Sinnlosigkeit erzeugt Stress.”

Verbindlich – Zuverlässig - Eigenverantwortlich

Richtwert zur Geschwindigkeit bei Vorträgen/Filmen: 2,16 Worte/Sekunde.

“Die Leichen der Pioniere pflastern die Straßen zum Erfolg.“ (Quelle: Dr. Schöpf)

„To play general after the war.”

“Der Fertiggucker: Kommt immer, wenn alles fertig ist und gibt dann seine Ratschläge dazu.“

„To pitch: Jemandem etwas schmackhaft machen.“ (Quelle: www.leo.org)

Integrity == „Das Richtige tun.“

Compliance == „Einhaltung von Regeln.“

Reduzierung Fertigungstiefe
> *„Do more of the same.“*

Erprobte Verfahren: „Leading practices“

„Neckbreaker“.

*„Ein Künstler ist jemand, der das Misslungene erkennen kann.“ (Peter Zumthor)* à Gilt auch für Ingenieurskunst!

Bewertungskompetenz

“If in doubt, ask!”

„If we wait until we‘re ready we’ll be waiting for the rest of our lives.”

“Man benötigt immer weniger Intelligenz um eine These aufzustellen als man braucht um sie zu widerlegen.“ (Quelle: Unbekannt).
> *„Only those who will risk going too far can possibly find out how far one can go.” (Quelle: T.S. Eliot)*
>
> *„Meaning is generated by imagining rather than by working.” (Quelle: Yuval Noah Harari, "Homo Deus: Eine Geschichte von Morgen")*

> *„The meaning of life is always a fictional story created by us humans.” (Quelle: Yuval Noah Harari, "Homo Deus: Eine Geschichte von Morgen")*

> *„One accurate measurement is worth a thousand expert opinions.” (Grace Hopper)*

„Wie soll ich glauben was du sagst, wenn ich sehe was du machst?“

„Walk the talk.“ (Tue was du sagst).

“You get what you pay.”

“Go and see!” (Management-Methode Prof. Dr. Roßdeutscher)
> *“Der Unterschied zwischen Theorie und Praxis ist in der Praxis größer als in der Theorie.“ (Quelle: Unbekannt)*

„Alles nur Ausführende. Niemand will die Verantwortung übernehmen.“

Arbeit 4.o:

- Selbstorganisierte Zusammenarbeit
- Selbstinitiative und Kreativität
- Verantwortung übernehmen
- **Activity Based Working** (à Dort arbeiten, wo es am produktivsten funktioniert).
- „Die Entlohnungsfrage ist komplex.“

## VERANTWORTUNGSDIFFUSION.
Verantwortungsdiffusion, auch als "Bystander-Effekt" bezeichnet, ist ein sozialpsychologisches Phänomen, bei dem Einzelpersonen in einer Gruppe weniger wahrscheinlich Verantwortung übernehmen, wenn andere Personen in der Nähe sind. Dieses Phänomen tritt auf, weil sich die Verantwortung auf mehrere Personen in der Gruppe zu verteilen scheint, wodurch jede Einzelperson weniger wahrscheinlich das Gefühl hat, persönlich handeln zu müssen.

“Den Arbeitsplatz zu dem machen, wie er eigentlich gedacht ist: Ein Ort, an dem anspruchsvolle Leistung geschieht, ein Auskommen ermöglicht wird und der allen Beteiligten Augenhöhe, Sinnstiftung, Erfüllung, Selbstwert und Dazugehörigkeit vermittelt.“ (Quelle: unbekannt, Psychosoziales Führungswissen.)

*Aufgabe: Themenfeld Simulation: Vorwissen der Studierenden?*

CAD, Simulation, Digitale Fabrik

Virtuelle Produktentwicklung

Es existiert eine Vielzahl verschiedener Softwarewerkzeuge zur Simulation verschiedener Produkteigenschaften. Anbindung an CAD, Vernetzung, Solver, Visualisierung. Gekoppelte Softwarewerkzeuge, Schnittstellen, Datenformate, tlw. proprietär.

Finite-Elemente-Simulation (u.a. Mechanisches und thermodynamisches Verhalten, tlw. Betriebsfestigkeit)

- Anders‘ Fazit: Die Simulation reduziert nicht den Aufwand für den Erkenntnisgewinn. Sie macht es aber möglich, den Erkenntnisgewinn zu einem früheren Zeitpunkt zu erhalten.

Ein *k-Means-Algorithmus* ist ein Verfahren zur Vektorquantisierung, das auch zur Clusteranalyse verwendet wird. Dabei wird aus einer Menge von ähnlichen Objekten eine vorher bekannte Anzahl von k Gruppen gebildet. Der Algorithmus ist eine der am häufigsten verwendeten Techniken zur Gruppierung von Objekten, da er schnell die Zentren der Cluster findet. Dabei bevorzugt der Algorithmus Gruppen mit geringer Varianz und ähnlicher Größe (Quelle: Wikipedia).

# Optionale Themen
Vergabe von Werk- und Dienstverträgen; Was unterscheidet einen Werk- von einem Dienstvertrag? Problem Verbot von Eingliederung.



ChatGPT


Der Begriff "schöpferische Zerstörung" wurde vom österreichisch-amerikanischen Ökonomen Joseph Schumpeter geprägt und bezieht sich auf einen Prozess des wirtschaftlichen Wandels, bei dem neue Innovationen und Technologien bestehende Geschäftsmodelle, Produkte und Strukturen verdrängen oder überholen. Dieser Begriff betont, dass die Einführung neuer Ideen und Innovationen oft mit der Ablösung und "Zerstörung" älterer, weniger effizienter Methoden einhergeht, was jedoch im Endeffekt zu positiven Veränderungen und Fortschritt führt.

In Schumpeters Theorie der schöpferischen Zerstörung sind folgende Hauptkonzepte enthalten:

1\. \*\*Innovation:\*\* Neue Ideen, Technologien oder Geschäftsmodelle werden entwickelt und eingeführt, um bestehende Lösungen zu verbessern oder zu ersetzen.

2\. \*\*Marktveränderung:\*\* Die Einführung von Innovationen führt oft dazu, dass sich der Markt und die Wettbewerbslandschaft verändern. Unternehmen müssen sich anpassen oder riskieren, irrelevant zu werden.

3\. \*\*Wirtschaftlicher Fortschritt:\*\* Obwohl die Einführung neuer Ideen oft mit dem Abbau von bestehenden Strukturen verbunden ist, führt sie langfristig zu wirtschaftlichem Fortschritt, Wachstum und Wohlstand.

4\. \*\*Kreativer Prozess:\*\* Die schöpferische Zerstörung betont den kreativen Prozess der Neuerfindung und Innovation als treibende Kraft hinter dem wirtschaftlichen Wandel.

5\. \*\*Struktureller Wandel:\*\* Die Veränderungen durch die schöpferische Zerstörung können tiefgreifend sein und ganze Branchen, Geschäftsmodelle oder Arbeitsweisen betreffen.

Ein bekanntes Beispiel für schöpferische Zerstörung ist der Übergang von traditionellen Telefonen zu Mobiltelefonen. Die Einführung von Mobiltelefonen hat das Geschäftsmodell der herkömmlichen Telefongesellschaften beeinflusst und verändert, während gleichzeitig neue Technologien, Dienstleistungen und Möglichkeiten geschaffen wurden.

Schumpeters Theorie betont, dass diese Dynamik der schöpferischen Zerstörung eine natürliche und notwendige Komponente des wirtschaftlichen Wachstums und Fortschritts ist, da sie veraltete Systeme erneuert und Platz für Neues schafft.


Bei der Strukturanalyse mit Hilfe von Simulation im Produktentstehungsprozess gibt es mehrere wichtige Aufgaben. Hier sind einige der Hauptaufgaben:

1\. Modellierung der Geometrie und Materialien: Eine der ersten Aufgaben besteht darin, die geometrische Struktur des Produkts zu modellieren und die Materialien korrekt zuzuweisen. Dies beinhaltet die Erstellung eines präzisen 3D-Modells mit den entsprechenden Abmessungen und Eigenschaften der Bauteile.

2\. Festlegung der Belastungen und Grenzbedingungen: Die Belastungen, denen das Produkt ausgesetzt sein wird, müssen definiert werden. Dies umfasst sowohl externe Kräfte, wie z. B. Gewichtsbelastungen oder Betriebslasten, als auch Randbedingungen, wie z. B. Lagerungen oder Einspannungen. Die korrekte Festlegung der Belastungen und Grenzbedingungen ist entscheidend für eine realistische Analyse.

3\. Festigkeitsbewertung und Materialanalyse: Eine genaue Analyse der verwendeten Materialien und ihrer mechanischen Eigenschaften ist wichtig. Dazu gehört die Bestimmung der Materialfestigkeit, Steifigkeit und Zähigkeit. Dies ermöglicht eine realistische Modellierung des Materialverhaltens und die Bewertung der Strukturfestigkeit.

4\. Durchführung der Strukturanalyse: Auf Basis des Modells und der definierten Belastungen wird die Strukturanalyse durchgeführt. Dies kann mithilfe von Methoden wie der Finite-Elemente-Methode (FEM) erfolgen. Dabei werden Spannungen, Deformationen und Verformungen innerhalb des Produkts analysiert, um die strukturelle Integrität und Festigkeit zu bewerten.

5\. Analyse der Ergebnisse: Nach Abschluss der Simulation werden die Ergebnisse analysiert. Dies umfasst die Bewertung von Spannungsverteilungen, Verformungen, Verzerrungen und Versagenskriterien. Aufgrund der Analyse können potenzielle Schwachstellen oder Bereiche mit übermäßiger Beanspruchung identifiziert werden.

6\. Optimierung und Designverbesserung: Auf Grundlage der Strukturanalyse können Ingenieure Optimierungsmaßnahmen ergreifen und Designverbesserungen vornehmen, um die Strukturfestigkeit und Steifigkeit des Produkts zu verbessern. Dies kann die Anpassung von Geometrie, Materialien oder Baugruppenkonzepten umfassen, um kritische Bereiche zu verstärken oder potenzielle Schwachstellen zu minimieren.

7\. Validierung und Verifikation: Die Ergebnisse der Strukturanalyse müssen mit realen Messdaten oder experimentellen Tests validiert und verifiziert werden. Dies dient dazu, die Genauigkeit und Zuverlässigkeit der Simulation zu überprüfen und sicherzustellen, dass die Ergebnisse den tatsächlichen Bedingungen entsprechen.

Die Strukturanalyse mit Hilfe von Simulation ermöglicht es Ingenieuren, das Verhalten eines Produkts unter verschiedenen Belastungen vorherzusagen, Schwachstellen zu erkennen und geeignete Maßnahmen zu ergreifen, um die Strukturfestigkeit und Sicherheit des Produkts zu verbessern. Durch die Durchführung einer umfassenden Strukturanalyse

Bei der thermischen Analyse mit Hilfe von Simulation im Produktentstehungsprozess gibt es mehrere wichtige Aufgaben. Hier sind einige der Hauptaufgaben:

1\. Wärmequellenanalyse: Eine der ersten Aufgaben besteht darin, die Wärmequellen im Produkt zu identifizieren. Dies umfasst beispielsweise elektrische Komponenten, Motoren oder andere Energiequellen, die Wärme erzeugen. Eine genaue Analyse der Wärmequellen ist wichtig, um die relevanten Bereiche für die thermische Analyse zu bestimmen.

2\. Wärmeleitfähigkeit und Materialanalyse: Die Kenntnis der thermischen Eigenschaften der Materialien im Produkt ist entscheidend. Dazu gehört die Bestimmung der Wärmeleitfähigkeit, spezifischen Wärmekapazität und Dichte der verwendeten Materialien. Dies ermöglicht eine realistische Modellierung der Wärmeübertragung.

3\. Modellierung der Geometrie und Grenzbedingungen: Die Modellierung der geometrischen Strukturen des Produkts ist ein wesentlicher Schritt. Dies umfasst die Erstellung eines 3D-Modells mit den entsprechenden Abmessungen und Eigenschaften. Ebenso wichtig ist die Festlegung der Grenzbedingungen, wie z.B. Umgebungstemperatur, Konvektion oder Wärmeübergangskoeffizienten an den Grenzflächen.

Bei der Zuverlässigkeits- und Lebensdaueranalyse mit Hilfe von Simulation im Produktentstehungsprozess gibt es mehrere wichtige Aufgaben:

1\. Belastungsprofile definieren: Eine der ersten Aufgaben besteht darin, die typischen Belastungsprofile zu definieren, denen das Produkt während seiner Lebensdauer ausgesetzt sein wird. Dies umfasst mechanische Belastungen wie Vibrationen, Stoßbelastungen, Biegung oder Druck, aber auch thermische oder elektrische Belastungen. à **Stichworte: Lastkollektiv**

2\. Materialanalyse und Festigkeitsbewertung: Eine genaue Analyse der verwendeten Materialien und ihrer mechanischen Eigenschaften ist entscheidend. Dazu gehört die Bestimmung der Materialfestigkeit, Steifigkeit und Zähigkeit. Dies ermöglicht eine realistische Modellierung des Materialverhaltens und die Bewertung der Lebensdauer.

3\. Modellierung der Geometrie und Baugruppen: Die Modellierung der geometrischen Strukturen und Baugruppen des Produkts ist ein wesentlicher Schritt. Dies umfasst die Erstellung eines 3D-Modells mit den entsprechenden Abmessungen und Materialeigenschaften. Die Berücksichtigung der Interaktionen zwischen den Bauteilen ist wichtig, um die Belastungen und Beanspruchungen korrekt abzubilden.

4\. Durchführung der Lebensdaueranalyse: Auf Basis des Modells und der festgelegten Belastungsprofile wird die Lebensdaueranalyse durchgeführt. Dies kann mithilfe von Methoden wie der Finite-Elemente-Methode (FEM) oder der Betriebsfestigkeitsanalyse erfolgen. Dabei werden die Spannungen, Deformationen und Beanspruchungen innerhalb des Produkts analysiert.

5\. Bewertung der Lebensdauer und Ermüdungsanalyse: Anhand der Simulationsergebnisse kann die erwartete Lebensdauer des Produkts bewertet werden. Dies umfasst die Analyse von Ermüdungsphänomenen wie Rissbildung, Bruch oder plastische Verformung, die aufgrund wiederholter Belastungen auftreten können. **à Stichworte: Betriebsfestigkeit, Wöhler-Linien**.

6\. Optimierung und Designverbesserung: Auf Grundlage der Lebensdaueranalyse können Ingenieure Optimierungsmaßnahmen ergreifen und Designverbesserungen vornehmen, um die Lebensdauer und Zuverlässigkeit des Produkts zu verbessern. Dies kann die Anpassung von Geometrie, Materialien oder Baugruppenkonzepten umfassen, um kritische Bereiche zu verstärken oder potenzielle Schwachstellen zu minimieren.

7\. Validierung und Verifikation: Die Ergebnisse der Lebensdaueranalyse müssen mit realen Messdaten oder experimentellen Tests validiert und verifiziert werden. Dies dient dazu, die Genauigkeit und Zuverlässigkeit der Simulation zu überprüfen und sicherzustellen, dass die Ergebnisse den tatsächlichen Bedingungen entsprechen.

Die Zuverlässigkeits- und Lebensdaueranalyse mit Hilfe von Simulation ermöglicht es Ingenieuren, das Verhalten eines Produkts unter verschiedenen Belastungen vorherzusagen, potenzielle Schwachstellen zu erkennen und geeignete Maßnahmen zu ergreifen, um die Lebensdauer und Zuverlässigkeit des Produkts zu

4\. Durchführung der thermischen Simulation: Auf Basis des Modells und der festgelegten Parameter wird die eigentliche thermische Simulation durchgeführt. Dies kann mit Hilfe von Software für die Computational Fluid Dynamics (CFD) oder Finite-Elemente-Methode (FEM) erfolgen. Dabei werden Wärmeübertragungsmechanismen wie Wärmeleitung, Konvektion und Strahlung berücksichtigt.

5\. Analyse der Ergebnisse: Nach Abschluss der Simulation werden die Ergebnisse analysiert. Dies umfasst die Bewertung von Temperaturverteilungen, Wärmeflüssen, Temperaturgradienten und potenziellen Hotspots im Produkt. Durch die Analyse können Schwachstellen oder Bereiche mit übermäßiger Erwärmung identifiziert werden.

6\. Optimierung und Designverbesserung: Auf Grundlage der Simulationsergebnisse können Ingenieure Optimierungsmaßnahmen ergreifen und Designverbesserungen vornehmen, um das thermische Verhalten des Produkts zu optimieren. Dies kann die Anpassung von Materialien, die Umgestaltung von Kühlkörpern oder die Veränderung von Lüftungsöffnungen umfassen.

7\. Validierung und Verifikation: Die Ergebnisse der thermischen Simulation müssen mit realen Messdaten oder experimentellen Tests validiert und verifiziert werden. Dies dient dazu, die Genauigkeit und Zuverlässigkeit der Simulation zu überprüfen und sicherzustellen, dass die Ergebnisse den tatsächlichen Bedingungen entsprechen.

Die thermische Analyse mit Hilfe von Simulation ermöglicht es Ingenieuren, das Wärmeverhalten eines Produkts vorherzusagen, Probleme zu erkennen und geeignete Maßnahmen zu ergreifen, um eine effektive Kühlung oder Wärmemanagement zu gewährleisten. Dadurch können Produkte verbessert, Energieeffizienz

Bei der akustischen Analyse mit Hilfe von Simulation im Produktentstehungsprozess gibt es mehrere wichtige Aufgaben:

1\. Modellierung der Geometrie: Eine der ersten Aufgaben besteht darin, die geometrische Struktur des Produkts zu modellieren. Dies beinhaltet die Erstellung eines präzisen 3D-Modells mit den entsprechenden Abmessungen und Formen der Bauteile. Die genaue Modellierung der Geometrie ist wichtig, um akustische Phänomene korrekt abzubilden.

2\. Festlegung der Quellen: Die Identifikation und Festlegung der akustischen Quellen im Produkt ist entscheidend. Dies können beispielsweise Motoren, Lüfter, Pumpen oder andere Schall erzeugende Komponenten sein. Die genaue Bestimmung der Quellen ermöglicht eine realistische Simulation des Schallfeldes.

3\. Materialdaten und Oberflächenbeschaffenheit: Die Kenntnis der akustischen Eigenschaften der verwendeten Materialien und deren Oberflächenbeschaffenheit ist wichtig. Dazu gehört die Bestimmung der Schallabsorptionskoeffizienten, Schalldämpfungseigenschaften und Reflexionsverhalten der Oberflächen. Diese Daten sind entscheidend für eine genaue Simulation des Schalls.

4\. Durchführung der akustischen Simulation: Auf Basis des Modells und der festgelegten Quellen wird die akustische Simulation durchgeführt. Dies kann mithilfe von Methoden wie der Finite-Elemente-Methode (FEM) oder der Boundary Element Method (BEM) erfolgen. Dabei werden Schallausbreitung, Resonanzen und Schallfelder innerhalb des Produkts analysiert.

5\. Analyse der Ergebnisse: Nach Abschluss der Simulation werden die akustischen Ergebnisse analysiert. Dies umfasst die Bewertung von Schalldruckpegeln, Schallleistung, Schallspektren und möglichen Schallproblemen im Produkt. Durch die Analyse können Bereiche mit erhöhter Lärmbelastung oder störenden Schallquellen identifiziert werden.

6\. Optimierung und Designverbesserung: Auf Grundlage der akustischen Analyse können Ingenieure Optimierungsmaßnahmen ergreifen und Designverbesserungen vornehmen, um die akustische Performance des Produkts zu verbessern. Dies kann die Auswahl geeigneter Schalldämpfungsmaterialien, die Neugestaltung von Komponenten oder die Verbesserung der Schalldämmung umfassen.

7\. Validierung und Verifikation: Die Ergebnisse der akustischen Simulation müssen mit realen Messdaten oder experimentellen Tests validiert und verifiziert werden. Dies dient dazu, die Genauigkeit und Zuverlässigkeit der Simulation zu überprüfen und sicherzustellen, dass die Ergebnisse den tatsächlichen Bedingungen entsprechen.

Die akustische Analyse mit Hilfe von Simulation ermöglicht es Ingenieuren, das Schallverhalten eines Produkts vorherzusagen, störende Geräusche zu identifizieren und geeignete Maßnahmen zur Geräuschreduzierung zu ergreifen. Dadurch können Produkte leiser und komfortabler gestaltet werden.


Finite-Elemente-Simulation. 

In der Produktentwicklung kommen verschiedene Arten von numerischen Simulationen zum Einsatz. Hier sind einige der gängigsten Arten und ihre Unterscheidungsmerkmale:

1\. Finite-Elemente-Methode (FEM): Die Finite-Elemente-Methode ist eine weit verbreitete numerische Methode, die zur Lösung von Differentialgleichungen verwendet wird. Sie basiert auf der Diskretisierung eines kontinuierlichen Systems in kleinere, finitielemente Teilbereiche. Die FEM ermöglicht die Modellierung von komplexen Geometrien, Materialverhalten und Randbedingungen. Sie ist vielseitig einsetzbar und eignet sich für strukturelle, thermische, strömungsmechanische und elektromagnetische Analysen.

2\. Computational Fluid Dynamics (CFD): Die Computational Fluid Dynamics beschäftigt sich mit der numerischen Simulation von Strömungsphänomenen. Sie ermöglicht die Analyse von Fluidströmungen, Druckverteilungen, Geschwindigkeiten, Temperaturen und anderen strömungsbezogenen Größen. CFD wird in der Produktentwicklung eingesetzt, um aerodynamische, hydrodynamische und thermische Effekte zu untersuchen, z. B. bei der Entwicklung von Fahrzeugen, Flugzeugen, Pumpen oder Klimaanlagen.

3\. Mehrkörpersimulation (MKS): Die Mehrkörpersimulation befasst sich mit der dynamischen Analyse von Systemen, die aus mehreren miteinander verbundenen Körpern bestehen. Sie ermöglicht die Modellierung von kinematischen und dynamischen Verhaltensweisen, wie z. B. Bewegungen, Kräfte, Momente und Kollisionen. MKS wird häufig in der Fahrzeugtechnik, Robotik, Maschinenbau und anderen Anwendungen eingesetzt, bei denen das Verhalten komplexer beweglicher Komponenten untersucht werden muss.

5\. Elektromagnetische Simulation: Elektromagnetische Simulationen werden zur Analyse von elektromagnetischen Feldern, elektrischen Strömen, Magnetfeldern und anderen elektromagnetischen Phänomenen eingesetzt. Sie ermöglichen die Untersuchung von Effekten wie elektromagnetischer Verträglichkeit (EMV), Antennenentwurf, Hochfrequenzverhalten und elektrischer Maschinenentwicklung.

Die Unterschiede zwischen den verschiedenen Arten von numerischen Simulationen liegen in den zugrundeliegenden mathematischen Modellen, der Art der Diskretisierung, den Anwendungsbereichen und den spezifischen Lösungsmethoden. Jede Art von Simulation hat ihre eigenen Stärken und Einschränkungen, und die Wahl der geeigneten Methode hängt von den spezifischen Anforderungen der zu analysierenden physikalischen Phänomene und der Komplexität des Systems ab.

Beispiel für eine andere Art von Simulationssystem: SPICE

Das Softwaresystem SPICE (Simulation Program with Integrated Circuit Emphasis) ist ein typisches Werkzeug zur Durchführung von Schaltungssimulationen. SPICE ist eine Art von Simulationswerkzeug, das speziell für die Analyse und das Verhalten von elektronischen Schaltungen entwickelt wurde. Es ermöglicht die Modellierung und Simulation von analogen, digitalen und gemischten Schaltungen, einschließlich Transistoren, Widerständen, Kondensatoren, Induktivitäten und anderen elektronischen Bauelementen. SPICE wird in der Elektronikindustrie weit verbreitet eingesetzt, um das Verhalten von integrierten Schaltungen (ICs), Leiterplatten, Verstärkern, Filtern und anderen elektronischen Systemen zu analysieren und zu optimieren.



## BURN-DOWN-CHART
Ein Burn-Down-Chart (auch als Burn-Down-Diagramm bezeichnet) ist ein visuelles Instrument im Projektmanagement, das hauptsächlich in agilen Methoden wie Scrum verwendet wird, um den Fortschritt bei der Umsetzung von Aufgaben oder User Stories über einen bestimmten Zeitraum zu verfolgen. Es dient dazu, den verbleibenden Aufwand oder die noch zu erledigende Arbeit im Laufe der Zeit zu visualisieren und somit das Team und die Stakeholder über den Projektfortschritt zu informieren.

Das Burn-Down-Chart besteht aus zwei Hauptkomponenten:

1\. \*\*Die Y-Achse (Vertikale Achse):\*\* Diese Achse zeigt den Umfang der Arbeit oder die geschätzten Aufwände an. Typischerweise wird der Arbeitsumfang in Story Points, Stunden oder anderen relevanten Einheiten dargestellt.

2\. \*\*Die X-Achse (Horizontale Achse):\*\* Diese Achse repräsentiert den Zeitverlauf. Sie kann in Tagen, Iterationen oder anderen Zeiteinheiten dargestellt werden, abhängig von der Projektstruktur.

Das Burn-Down-Chart startet mit dem gesamten Umfang der Arbeit oder den geplanten Aufwänden am Anfang des Projekts. Im Laufe der Zeit wird der tatsächlich erledigte Umfang oder die abgeschlossenen Aufgaben von Tag zu Tag oder Iteration zu Iteration von oben nach unten abgetragen (daher "Burn-Down"). Die ideale Linie im Diagramm zeigt den erwarteten Fortschritt gemäß dem geplanten Tempo und hilft dabei, Abweichungen zu erkennen.

![](Aspose.Words.e14cf7f3-6a3e-4150-b56e-2ba738c551dd.002.png)

Es gibt zwei Hauptvarianten von Burn-Down-Charts:

\- \*\*Aufgaben-basiertes Burn-Down-Chart:\*\* Hier werden einzelne Aufgaben oder User Stories aufgeführt, und das Team markiert sie, sobald sie erledigt sind. Der Chart zeigt den Fortschritt dieser spezifischen Aufgaben über die Zeit.

\- \*\*Zeit-basiertes Burn-Down-Chart:\*\* Dieser Ansatz berücksichtigt die insgesamt verbleibende Arbeit über den Verlauf der Zeit, ohne auf einzelne Aufgaben einzugehen. Es zeigt den Trend, wie viel Arbeit noch übrig ist und ob das Team im Plan liegt.

Burn-Down-Charts sind äußerst nützlich, um den Projektfortschritt auf einen Blick zu erfassen, Engpässe oder Verzögerungen zu erkennen und rechtzeitig Anpassungen vorzunehmen, um sicherzustellen, dass das Projektziel erreicht wird. Sie unterstützen die Kommunikation im Team und mit Stakeholdern und fördern eine transparente und agile Projektumsetzung.

# SOFTWAREENTWICKLUNG
## BROWNFIELD
In der Softwareentwicklung bezieht sich der Begriff "Brownfield" auf ein Projekt oder eine Softwareanwendung, die bereits existiert und aktiv genutzt wird, im Gegensatz zu einem "Greenfield"-Projekt, bei dem von Grund auf neu begonnen wird. Brownfield-Projekte beziehen sich auf die Weiterentwicklung, Erweiterung oder Wartung bestehender Software oder Systeme.

Hier sind einige Merkmale und Aspekte, die Brownfield-Projekte charakterisieren:

1\. \*\*Vorhandene Systeme:\*\* Brownfield-Projekte beziehen sich auf Softwareanwendungen oder Systeme, die bereits entwickelt wurden und in der Produktion oder im Einsatz sind.

2\. \*\*Erweiterung und Wartung:\*\* Brownfield-Entwicklung umfasst oft die Erweiterung oder Modifikation von bestehendem Code, um neue Funktionalitäten hinzuzufügen oder bestehende zu aktualisieren.

3\. \*\*Herausforderungen der Legacy-Systeme:\*\* Oftmals sind Brownfield-Projekte mit Legacy-Systemen verbunden, die ältere Technologien und Architekturen verwenden. Die Modernisierung und Aktualisierung solcher Systeme kann herausfordernd sein.

4\. \*\*Risiken und Komplexität:\*\* Aufgrund der Vorhandenseins von bestehendem Code und Systemen kann die Entwicklung in einem Brownfield-Kontext komplexer sein. Neue Änderungen müssen in bestehende Strukturen integriert werden, was Risiken für unerwartete Auswirkungen mit sich bringen kann.

5\. \*\*Verständnis des bestehenden Codes:\*\* Entwickler, die an Brownfield-Projekten arbeiten, müssen den bestehenden Code gut verstehen, um effizient Änderungen vornehmen und Fehler beheben zu können.

6\. \*\*Legacy-Code:\*\* Oftmals wird Brownfield-Entwicklung mit dem Umgang mit Legacy-Code verbunden, der veraltet, unstrukturiert oder unzureichend dokumentiert sein kann.

7\. \*\*Schrittweise Verbesserung:\*\* Brownfield-Projekte setzen oft auf schrittweise Verbesserung und Modernisierung, anstatt das gesamte System auf einmal neu zu erstellen.

8\. \*\*Integration und Datenmigration:\*\* Bei Brownfield-Projekten muss oft darauf geachtet werden, wie neue Funktionalitäten und Änderungen mit bestehenden Daten und Systemen integriert werden können.

Die Brownfield-Entwicklung ist eine Realität in vielen Unternehmen, da sie oft bestehende Investitionen in Software- und Systementwicklungen nutzen und darauf aufbauen. Sie erfordert spezielle Fähigkeiten und Ansätze, um effizient und erfolgreich Änderungen in einem bereits bestehenden Umfeld durchzuführen.

## SCRUM
\*\*Die wichtigsten Kennzeichen von SCRUM-Projekten:\*\*

Scrum ist eine agile Projektmanagement-Methode, die darauf abzielt, die Entwicklung von Software und anderen Produkten durch iterative, inkrementelle und kollaborative Ansätze zu optimieren. Hier sind einige der wichtigsten Kennzeichen von Scrum-Projekten:

1\. \*\*Iterative Entwicklung:\*\* Scrum-Projekte sind in Iterationen, sogenannten Sprints, organisiert. Jeder Sprint hat eine festgelegte Dauer, typischerweise 1 bis 4 Wochen. Während eines Sprints wird ein funktionsfähiges Inkrement des Produkts entwickelt.

2\. \*\*Inkrementelle Entwicklung:\*\* Nach jedem Sprint wird ein neues, inkrementelles Produktinkrement erstellt. Dies ermöglicht es, kontinuierlich Fortschritte zu verfolgen und Feedback zu erhalten.

3\. \*\*Rollen und Verantwortlichkeiten:\*\* Scrum definiert klare Rollen wie den Product Owner, den Scrum Master und das Entwicklerteam. Jede Rolle hat spezifische Verantwortlichkeiten, die zur effektiven Projektumsetzung beitragen.

4\. \*\*Selbstorganisierte Teams:\*\* Scrum-Teams sind selbstorganisiert und multifunktional. Sie treffen gemeinsam Entscheidungen, wie sie die Arbeitsaufgaben im Sprint erfüllen.

5\. \*\*Priorisierung durch den Product Owner:\*\* Der Product Owner ist für die Priorisierung der Aufgaben im Backlog verantwortlich, basierend auf den Anforderungen des Kunden und des Marktes.

6\. \*\*Kurze Planungs- und Review-Meetings:\*\* Am Anfang jedes Sprints gibt es ein Sprint-Planning-Meeting, in dem das Team die zu erledigenden Aufgaben auswählt und schätzt. Am Ende des Sprints findet ein Sprint-Review-Meeting statt, in dem das entwickelte Inkrement vorgestellt wird.

7\. \*\*Tägliche Stand-up-Meetings:\*\* Das Team hält täglich kurze Stand-up-Meetings ab, in denen die Mitglieder über ihren Fortschritt, Hindernisse und Pläne berichten.

8\. \*\*Flexibilität und Anpassung:\*\* Scrum-Projekte sind darauf ausgelegt, Änderungen in den Anforderungen flexibel zu handhaben. Neue Anforderungen können in den Backlog aufgenommen und in zukünftigen Sprints berücksichtigt werden.

\*\*Unterschiede von Scrum zu bisherigen Vorgehensweisen der Softwareentwicklung:\*\*

Scrum unterscheidet sich von traditionellen Wasserfall- oder sequentiellen Ansätzen der Softwareentwicklung auf folgende Weise:

1\. \*\*Flexibilität vs. Starrheit:\*\* Scrum ermöglicht Flexibilität und Anpassung während des gesamten Projekts, während traditionelle Ansätze oft starre Pläne haben.

2\. \*\*Inkrementelle Entwicklung vs. Monolithische Entwicklung:\*\* Scrum betont die schrittweise Entwicklung von Produktinkrementen, im Gegensatz zu einer großen, monolithischen Endlieferung.

3\. \*\*Fokus auf Kollaboration vs. Isolation:\*\* Scrum fördert die Zusammenarbeit zwischen den Teammitgliedern und den Stakeholdern, während traditionelle Ansätze isolierte Teams haben könnten.

4\. \*\*Kontinuierliches Feedback vs. Spätes Feedback:\*\* Scrum ermöglicht kontinuierliches Feedback durch regelmäßige Reviews, während traditionelle Ansätze oft erst spät im Entwicklungsprozess Feedback erhalten.

5\. \*\*Selbstorganisation vs. Top-Down-Ansatz:\*\* Scrum-Teams sind selbstorganisiert und treffen gemeinsam Entscheidungen, im Gegensatz zu einer stärkeren Hierarchie in traditionellen Ansätzen.

6\. \*\*Kontinuierlicher Fortschritt vs. Phasenfortschritt:\*\* Scrum betont den kontinuierlichen Fortschritt, während traditionelle Ansätze oft in definierten Phasen ablaufen.

Insgesamt fördert Scrum eine agilere und flexiblere Herangehensweise an die Softwareentwicklung, die besser auf sich ändernde Anforderungen und Marktbedingungen reagieren kann.

### AGILE MANIFEST
Das Agile Manifest, das im Jahr 2001 von 17 führenden Köpfen der Softwareentwicklung, darunter Ken Schwaber, erstellt wurde, enthält vier zentrale Wertedeklarationen und zwölf Prinzipien, die die Grundlage für agile Methoden wie Scrum bilden. Ken Schwaber gehört zu den Mitbegründern von Scrum und hat maßgeblich zur Entwicklung agiler Methoden beigetragen. Hier sind die wichtigsten Aussagen des Agilen Manifests:

\*\*Wertedeklarationen:\*\*

1\. \*\*Individuen und Interaktionen über Prozesse und Werkzeuge:\*\* Dies bedeutet, dass der Fokus auf die Menschen und ihre Zusammenarbeit gelegt wird, da erfolgreiche Softwareentwicklung von effektiver Kommunikation und Zusammenarbeit abhängt.

2\. \*\*Funktionierende Software über umfassende Dokumentation:\*\* Das Hauptziel ist es, funktionierende Software zu liefern, die den Kundenwünschen entspricht, anstatt sich ausschließlich auf ausführliche Dokumentation zu verlassen.

3\. \*\*Zusammenarbeit mit dem Kunden über Vertragsverhandlung:\*\* Statt lange Vertragsverhandlungen zu führen, betont dieses Prinzip die kontinuierliche Zusammenarbeit mit Kunden, um sicherzustellen, dass das Ergebnis ihren Bedürfnissen entspricht.

4\. \*\*Reagieren auf Veränderung über das Befolgen eines Plans:\*\* Agile Methoden sind darauf ausgerichtet, flexibel auf Veränderungen in Anforderungen, Marktbedingungen und Kundenwünschen zu reagieren, anstatt strikt einem vordefinierten Plan zu folgen.

\*\*Prinzipien:\*\*

Die zwölf Prinzipien des Agilen Manifests unterstreichen die Werte und bieten praktische Leitlinien für die Umsetzung agiler Methoden. Einige dieser Prinzipien umfassen:

1\. \*\*Frühe und kontinuierliche Auslieferung wertvoller Software.\*\*

2\. \*\*Änderungen willkommen heißen, auch in späteren Projektphasen.\*\*

3\. \*\*Häufige Zusammenarbeit zwischen Fachexperten und Entwicklern.\*\*

4\. \*\*Motivierte Individuen unterstützen und ihnen ein geeignetes Umfeld bieten.\*\*

5\. \*\*Fokus auf funktionsfähige Software als primärem Fortschrittsmaß.\*\*

6\. \*\*Nachhaltiges Arbeitstempo aufrechterhalten, um kontinuierlich Wert zu liefern.\*\*

7\. \*\*Laufende Aufmerksamkeit auf technische Exzellenz und gutes Design.\*\*

8\. \*\*Einfachheit in Design und Implementierung priorisieren.\*\*

9\. \*\*Selbstorganisierte Teams befähigen, Entscheidungen zu treffen.\*\*

10\. \*\*Regelmäßige Reflexionen zur Verbesserung des Prozesses durchführen.\*\*

Das Agile Manifest betont die Bedeutung der Flexibilität, Kollaboration, Feedback-Schleifen und kontinuierlichen Verbesserung in der Softwareentwicklung. Es hat die Grundlage für eine Vielzahl von agilen Methoden und Praktiken geschaffen, die darauf abzielen, effektive, hochwertige Softwareprodukte in enger Abstimmung mit den Kundenbedürfnissen zu entwickeln.
### 12 PRINZIPIEN
die zwölf Prinzipien des Agilen Manifests im Detail:

1\. Unsere höchste Priorität ist es, den Kunden durch frühe und kontinuierliche Auslieferung wertvoller Software zufrieden zu stellen.

2\. Heiße Veränderungen auch in späten Entwicklungsphasen willkommen. Agile Prozesse nutzen Veränderungen zum Wettbewerbsvorteil des Kunden.

3\. Liefere funktionierende Software regelmäßig, bevorzuge dabei das kürzere Zeitintervall zwischen wenigen Wochen bis wenigen Monaten, mit einer Vorliebe für die kürzere Zeitspanne.

4\. Arbeite mit Fachexperten und Entwicklern täglich zusammen, während des gesamten Projekts.

5\. Baue Projekte um motivierte Individuen. Gib ihnen das Umfeld und die Unterstützung, die sie benötigen, und vertraue darauf, dass sie die Arbeit erledigen.

6\. Die effizienteste und effektivste Methode, Informationen an und innerhalb eines Entwicklungsteams zu übermitteln, ist im Gespräch von Angesicht zu Angesicht.

7\. Funktionierende Software ist das primäre Maß für Fortschritt.

8\. Agile Prozesse fördern nachhaltige Entwicklung. Die Auftraggeber, Entwickler und Benutzer sollten ein gleichmäßiges Tempo über unbegrenzte Zeit halten können.

9\. Ständige Aufmerksamkeit für technische Exzellenz und gutes Design steigert die Agilität.

10\. Einfachheit – die Kunst der Maximierung der Arbeit, die nicht erledigt wird – ist essenziell.

11\. Die besten Architekturen, Anforderungen und Entwürfe entstehen aus selbstorganisierten Teams.

12\. In regelmäßigen Abständen reflektiert das Team über seine Effektivität und passt sein Verhalten entsprechend an.

### ROLLEN
Innerhalb von Scrum-Projekten gibt es drei wichtige Rollen, die für den reibungslosen Ablauf des agilen Entwicklungsprozesses von entscheidender Bedeutung sind. Diese Rollen tragen dazu bei, die Zusammenarbeit, die Verantwortlichkeiten und die Kommunikation im Team und mit den Stakeholdern zu strukturieren. Die wichtigsten Rollen in Scrum sind:

1\. \*\*Product Owner:\*\*



`   `Der Product Owner ist für die Maximierung des Werts des Produkts und des Projekts verantwortlich. Zu seinen Hauptaufgaben gehören:



`   `- \*\*Anforderungsmanagement:\*\* Der Product Owner erstellt und priorisiert den Produkt-Backlog, der alle Anforderungen und Aufgaben für das Projekt enthält.

`   `- \*\*Priorisierung:\*\* Der Product Owner entscheidet, welche Anforderungen im Backlog zuerst umgesetzt werden sollen und definiert, was als nächstes entwickelt wird.

`   `- \*\*Kommunikation mit Stakeholdern:\*\* Der Product Owner kommuniziert mit den Kunden, Benutzern und anderen Stakeholdern, um deren Anforderungen und Erwartungen zu verstehen.

`   `- \*\*Akzeptanzkriterien:\*\* Der Product Owner definiert klare Akzeptanzkriterien für jede Anforderung, um sicherzustellen, dass die Umsetzung den Kundenerwartungen entspricht.

2\. \*\*Scrum Master:\*\*

`   `Der Scrum Master ist für die Unterstützung des Teams verantwortlich, um sicherzustellen, dass der Scrum-Prozess richtig angewendet wird. Zu seinen Hauptaufgaben gehören:



`   `- \*\*Prozess-Fazilitator:\*\* Der Scrum Master unterstützt das Team bei der Umsetzung des Scrum-Frameworks, beseitigt Hindernisse und fördert die Einhaltung der Scrum-Prinzipien.

`   `- \*\*Kontinuierliche Verbesserung:\*\* Der Scrum Master fördert kontinuierliche Verbesserung, indem er regelmäßige Retrospektiven durchführt, in denen das Team den Entwicklungsprozess reflektiert und optimiert.

`   `- \*\*Schutz des Teams:\*\* Der Scrum Master schützt das Team vor externen Störungen und unterstützt bei der Aufrechterhaltung eines produktiven Arbeitsumfelds.

`   `- \*\*Kommunikation und Koordination:\*\* Der Scrum Master fördert die Kommunikation innerhalb des Teams und mit den Stakeholdern und sorgt für eine reibungslose Koordination der Aktivitäten.

3\. \*\*Entwicklerteam:\*\*

`   `Das Entwicklerteam ist verantwortlich für die Umsetzung der Aufgaben und die Entwicklung des Produkts. Das Team sollte selbstorganisiert sein und die Verantwortung für die Umsetzung tragen. Die Hauptaufgaben des Entwicklerteams sind:



`   `- \*\*Umsetzung von Aufgaben:\*\* Das Entwicklerteam wählt Aufgaben aus dem Produkt-Backlog aus und entwickelt die Funktionalitäten in den Sprints.

`   `- \*\*Selbstorganisation:\*\* Das Team organisiert sich selbst, plant die Aufgaben und entscheidet, wie sie am besten umgesetzt werden.

`   `- \*\*Kollaboration:\*\* Das Team arbeitet eng zusammen, teilt Wissen und unterstützt sich gegenseitig bei der Umsetzung.

`   `- \*\*Inkrementelle Entwicklung:\*\* Das Team liefert am Ende jedes Sprints ein funktionsfähiges Produktinkrement.

Diese drei Rollen – Product Owner, Scrum Master und Entwicklerteam – bilden das Kerngerüst eines Scrum-Projekts und arbeiten eng zusammen, um die Entwicklung und Lieferung von qualitativ hochwertiger Software sicherzustellen.

### AKTIVITÄTEN
In einem Scrum-Projekt gibt es eine Reihe von Aktivitäten, die im Rahmen des agilen Entwicklungsprozesses durchgeführt werden, um die kontinuierliche Entwicklung, Lieferung und Verbesserung des Produkts sicherzustellen. Hier sind die wichtigsten Aktivitäten innerhalb von Scrum-Projekten:

1\. \*\*Sprint Planning (Sprint-Planung):\*\*

`   `In dieser Aktivität wird der Inhalt des nächsten Sprints geplant. Das Entwicklungsteam wählt die zu bearbeitenden Aufgaben aus dem Produkt-Backlog aus und definiert die Zielsetzung des Sprints.

2\. \*\*Daily Scrum (Tägliches Stand-up-Meeting):\*\*

`   `Das Team trifft sich täglich für ein kurzes Meeting, bei dem jedes Teammitglied den Stand seiner Arbeit, mögliche Hindernisse und den Plan für den Tag teilt.

3\. \*\*Sprint Review (Sprint-Rückblick):\*\*

`   `Am Ende jedes Sprints wird eine Präsentation des entwickelten Produktinkrements durchgeführt. Das Team zeigt den Stakeholdern, was erreicht wurde, und sammelt Feedback.

4\. \*\*Sprint Retrospective (Sprint-Retrospektive):\*\*

`   `In dieser Aktivität reflektiert das Team über den abgeschlossenen Sprint und identifiziert, was gut gelaufen ist und was verbessert werden kann. Die Erkenntnisse werden genutzt, um den Prozess zu optimieren.

5\. \*\*Backlog Refinement (Produkt-Backlog-Verfeinerung):\*\*

`   `Der Product Owner und das Entwicklungsteam treffen sich regelmäßig, um den Produkt-Backlog zu überprüfen und neue Anforderungen oder Änderungen zu diskutieren. Ziel ist es, den Backlog für zukünftige Sprints vorzubereiten.

6\. \*\*Sprint Execution (Sprint-Ausführung):\*\*

`   `Während des Sprints arbeitet das Entwicklungsteam an der Umsetzung der ausgewählten Aufgaben. Es entwickelt, testet und integriert die Funktionalitäten, um das Ziel des Sprints zu erreichen.

7\. \*\*Task Breakdown (Aufgabenzerlegung):\*\*

`   `Das Entwicklungsteam zerlegt die ausgewählten Aufgaben in kleinere Aufgaben oder User Stories, um den Arbeitsaufwand besser einschätzen und verteilen zu können.

8\. \*\*Definition of Done (DoD):\*\*

`   `Das Entwicklungsteam definiert klare Kriterien, die erfüllt sein müssen, damit eine Aufgabe oder ein Feature als abgeschlossen gilt und in das Produktinkrement aufgenommen wird.

9\. \*\*Continuous Integration (Kontinuierliche Integration):\*\*

`   `Das Entwicklungsteam integriert regelmäßig den entwickelten Code, um sicherzustellen, dass alle Änderungen reibungslos zusammenarbeiten.

10\. \*\*Release Planning (Release-Planung):\*\*

`    `Der Product Owner und das Team planen die Veröffentlichungen des Produkts, indem sie entscheiden, welche Funktionalitäten in welchen Sprints entwickelt werden.

11\. \*\*Product Backlog Grooming (Produkt-Backlog-Pflege):\*\*

`    `Der Product Owner verfeinert den Produkt-Backlog, indem er die Prioritäten, Beschreibungen und Schätzungen der Anforderungen aktualisiert.

Diese Aktivitäten sind integrale Bestandteile des Scrum-Frameworks und dienen dazu, die Zusammenarbeit, Kommunikation und kontinuierliche Verbesserung im Team sicherzustellen und den Produktentwicklungsprozess agil und flexibel zu gestalten.

### DOKUMENTE UND ARTEFAKTE
In Scrum-Projekten wird der Schwerpunkt auf funktionierender Software und direkter Kommunikation gelegt, daher sind traditionelle umfangreiche Dokumente weniger präsent. Dennoch gibt es einige Dokumente und Artefakte, die im Scrum-Framework eine Rolle spielen, um die Kommunikation, Transparenz und den reibungslosen Ablauf des Projekts zu unterstützen. Hier sind die wichtigsten Dokumente innerhalb von Scrum-Projekten:

1\. \*\*Product Backlog:\*\*

`   `Der Produkt-Backlog ist eine Liste aller Anforderungen, Funktionalitäten und Aufgaben, die im Projekt umgesetzt werden sollen. Er wird vom Product Owner erstellt, gepflegt und priorisiert.

2\. \*\*Sprint Backlog:\*\*

`   `Der Sprint-Backlog enthält die Aufgaben, die das Entwicklungsteam im aktuellen Sprint umsetzen wird. Er wird während der Sprint-Planung aus dem Produkt-Backlog abgeleitet.

3\. \*\*Definition of Done (DoD):\*\*

`   `Die Definition of Done ist eine Liste von Kriterien, die erfüllt sein müssen, damit eine Aufgabe als abgeschlossen gilt. Sie stellt sicher, dass jede Aufgabe eine bestimmte Qualität erreicht hat.

4\. \*\*Product Increment:\*\*

`   `Das Produktinkrement ist das Ergebnis eines abgeschlossenen Sprints – eine funktionsfähige, erweiterte Version des Produkts, die bereit ist, ausgeliefert zu werden.

5\. \*\*Release Plan:\*\*

`   `Der Release-Plan zeigt die geplanten Veröffentlichungen des Produkts und die Funktionalitäten, die in jedem Sprint entwickelt werden sollen, um diese Veröffentlichungen zu erreichen.

6\. \*\*Burn-Down Chart:\*\*

`   `Das Burn-Down Chart visualisiert den Fortschritt des Teams im aktuellen Sprint, indem es zeigt, wie viel Arbeit noch erledigt werden muss, um die Sprintziele zu erreichen.

7\. \*\*Product Vision:\*\*

`   `Die Produktvision beschreibt die langfristige Vision des Produkts und den Wert, den es für die Kunden und das Unternehmen bringen soll. Sie dient als Leitfaden für die Priorisierung und Entscheidungsfindung.

8\. \*\*Release Notes:\*\*

`   `Obwohl nicht immer ein traditionelles Dokument, werden in agilen Projekten oft Release Notes erstellt, um Kunden und Stakeholder über die neuen Funktionen und Verbesserungen zu informieren.

9\. \*\*Akzeptanzkriterien:\*\*

`   `Akzeptanzkriterien sind eine wichtige Dokumentation für jede Aufgabe oder Anforderung im Produkt-Backlog. Sie beschreiben, wie das Team und der Product Owner erkennen können, dass die Arbeit abgeschlossen ist und den Erwartungen entspricht.

Es ist wichtig zu beachten, dass in Scrum die Fokussierung auf Kommunikation, Zusammenarbeit und funktionierende Software höher ist als die Erstellung umfangreicher Dokumentation. Die Dokumente dienen dazu, die Klarheit zu erhöhen, die Teamkommunikation zu unterstützen und den Stakeholdern Transparenz zu bieten.


In Scrum werden die Begriffe "Dokumente" und "Artefakte" oft verwendet, um auf verschiedene Arten von Informationen und Materialien im Projektumfeld hinzuweisen. Der Unterschied zwischen ihnen liegt in ihrer Natur, ihrem Zweck und ihrer Verwendung im agilen Entwicklungsprozess.

\*\*Dokumente:\*\*

Unter "Dokumenten" versteht man schriftliche oder elektronische Aufzeichnungen, die Informationen über verschiedene Aspekte des Projekts enthalten. Dokumente können detaillierte Beschreibungen, Anforderungen, Pläne, Berichte und andere schriftliche Materialien umfassen. Dokumente sind im Allgemeinen textbasiert und dienen dazu, Informationen zu erfassen, zu vermitteln und zu speichern. Sie können sowohl formell als auch informell sein und verschiedene Zwecke erfüllen, wie z. B. die Kommunikation von Anforderungen, die Dokumentation von Entscheidungen oder die Verfolgung des Projektfortschritts.

\*\*Artefakte:\*\*

"Artefakte" bezieht sich auf die konkreten Ausgaben oder Ergebnisse des agilen Entwicklungsprozesses, die zur Unterstützung des Projekts dienen. Artefakte sind physische oder virtuelle Elemente, die im Projektumfeld sichtbar sind und zur Dokumentation, Kommunikation und Überwachung verwendet werden. Im Kontext von Scrum sind Artefakte in der Regel von hoher Relevanz für das Team, die Stakeholder und den Projektfortschritt. Sie repräsentieren den aktuellen Stand des Projekts und fördern die Transparenz.

Einige der wichtigsten Artefakte in Scrum sind:

\- \*\*Product Backlog:\*\* Die Liste der Anforderungen und Funktionalitäten, die im Projekt entwickelt werden sollen.

\- \*\*Sprint Backlog:\*\* Die Liste der Aufgaben und Aufträge, die im aktuellen Sprint umgesetzt werden sollen.

\- \*\*Product Increment:\*\* Das Ergebnis eines abgeschlossenen Sprints, das das aktuelle, erweiterte Produkt repräsentiert.

\- \*\*Burn-Down Chart:\*\* Ein visuelles Diagramm, das den Fortschritt des Teams während des Sprints zeigt.

\- \*\*Definition of Done (DoD):\*\* Die Kriterien, die erfüllt sein müssen, damit eine Aufgabe oder ein Feature als abgeschlossen gilt.

Der Hauptunterschied zwischen Dokumenten und Artefakten liegt darin, dass Dokumente Informationen in schriftlicher oder elektronischer Form erfassen, während Artefakte konkrete Ergebnisse, Visualisierungen oder Ausgaben sind, die im Projektumfeld sichtbar sind und die aktuelle Situation des Projekts widerspiegeln. Beide spielen eine wichtige Rolle im agilen Projektmanagement und unterstützen die Kommunikation, Transparenz und den effektiven Projektverlauf.

Ein Artefakt in einem Scrum-Kontext unterscheidet sich von einem Dokument in seiner Form und Natur. Eigenschaften, die ein Artefakt haben muss, um eindeutig kein Dokument zu sein:

1\. \*\*Sichtbarkeit und Konkretheit:\*\*

`   `Ein Artefakt sollte physisch oder virtuell sichtbar sein und eine konkrete Darstellung oder Ausgabe des Projektergebnisses darstellen. Es kann visuell, interaktiv oder fassbar sein.

2\. \*\*Repräsentation eines Ergebnisses:\*\*

`   `Ein Artefakt sollte das Ergebnis eines Prozesses oder einer Aktivität repräsentieren. Es zeigt den Fortschritt, den Stand des Projekts oder die Umsetzung einer bestimmten Aufgabe.

3\. \*\*Greifbarkeit:\*\*

`   `Ein Artefakt kann von den Teammitgliedern und Stakeholdern direkt wahrgenommen oder genutzt werden. Es kann beispielsweise ein physischer Prototyp, ein Diagramm, ein Modell oder eine visuelle Darstellung sein.

4\. \*\*Veranschaulichung von Informationen:\*\*

`   `Ein Artefakt dient oft dazu, Informationen visuell oder konkret darzustellen. Es ermöglicht eine bessere Verständlichkeit und Kommunikation über den Zustand des Projekts oder die erreichten Ergebnisse.

5\. \*\*Aktuelle Relevanz:\*\*

`   `Ein Artefakt sollte den aktuellen Stand des Projekts widerspiegeln und keine statische Aufzeichnung vergangener Ereignisse oder Zustände sein.

6\. \*\*Unterstützung der Zusammenarbeit:\*\*

`   `Artefakte unterstützen die Zusammenarbeit im Team und die Kommunikation mit Stakeholdern, indem sie den Fortschritt, die Pläne oder die Umsetzung visuell vermitteln.

7\. \*\*Potenzial zur direkten Veränderung oder Manipulation:\*\*

`   `Ein Artefakt kann oft direkt beeinflusst, aktualisiert oder geändert werden, um den sich ändernden Projektanforderungen gerecht zu werden.

Ein klares Beispiel für ein Artefakt in Scrum könnte ein physischer Prototyp eines Produkts sein, der den aktuellen Stand der Entwicklung repräsentiert und als Grundlage für Diskussionen und Verbesserungen dient. Dieser Prototyp ist sichtbar, greifbar, repräsentiert den Fortschritt und unterstützt die Kommunikation und Zusammenarbeit im Team.


# SCHWARMORGANISATION
Schwarmorganisation, auch als Schwarmintelligenz oder kollektive Intelligenz bezeichnet, ist ein Konzept, das von Verhaltensweisen inspiriert ist, die in natürlichen Schwarmstrukturen in der Tierwelt, wie beispielsweise bei Bienen, Ameisen, Vögeln und Fischen, beobachtet werden. Dieses Konzept wurde in den Bereichen der Biologie, Informatik, Künstlichen Intelligenz (KI) und der Organisationstheorie erforscht und angewendet.

In einer Schwarmorganisation arbeiten viele autonome Individuen oder Agenten zusammen, um kollektiv komplexe Aufgaben zu lösen, ohne dass eine zentrale Kontrolle oder Führung erforderlich ist. Hier sind einige wichtige Aspekte der Schwarmorganisation:

1\. \*\*Dezentralisierung\*\*: In einer Schwarmorganisation agieren die Individuen autonom und reagieren auf ihre lokalen Umgebungen. Es gibt keine zentrale Steuerung, sondern eher einen emergenten Verhaltensstil, bei dem komplexe Muster aus den Interaktionen der Individuen entstehen.

2\. \*\*Selbstorganisation\*\*: Die Agenten in einer Schwarmorganisation organisieren sich selbst aufgrund lokaler Informationen und einfacher Regeln. Dadurch entstehen koordinierte Aktionen und kollektive Intelligenz, ohne dass eine übergeordnete Planung erforderlich ist.

3\. \*\*Anpassungsfähigkeit\*\*: Schwarmorganisationen sind in der Regel flexibel und anpassungsfähig, da sie auf Veränderungen in ihrer Umgebung reagieren können. Wenn sich die Bedingungen ändern, können die Agenten ihre Verhaltensweisen anpassen, um weiterhin effizient zu agieren.

4\. \*\*Robustheit\*\*: Die dezentrale Natur von Schwarmorganisationen führt oft zu Robustheit gegenüber individuellen Ausfällen oder Störungen. Das System kann weiterhin funktionieren, auch wenn einzelne Agenten ausfallen oder ihre Ziele ändern.

5\. \*\*Emergentes Verhalten\*\*: Ein bemerkenswertes Merkmal von Schwarmorganisationen ist das Entstehen von emergentem Verhalten, das auf den Interaktionen der Individuen basiert. Komplexe globale Muster und Verhaltensweisen können aus einfachen lokalen Regeln entstehen.

6\. \*\*Anwendungen\*\*: Schwarmorganisationen finden Anwendungen in verschiedenen Bereichen, einschließlich Robotik, Optimierung, Verkehrskontrolle, KI, Finanzmarktmodellierung und mehr. Beispiele sind selbstorganisierende Roboterschwärme, Verkehrsflussmodellierung oder auch die Analyse von sozialen Netzwerken.

Es ist wichtig zu beachten, dass Schwarmorganisationen zwar effektiv sein können, aber nicht für alle Situationen geeignet sind. Es gibt Herausforderungen wie die Koordination von Aktionen, das Vermeiden von Konflikten und die Sicherstellung der Qualität der kollektiven Entscheidungen. Dennoch haben die Konzepte der Schwarmorganisation das Verständnis für die Zusammenarbeit und Selbstorganisation in komplexen Systemen erweitert und bieten interessante Ansätze für die Lösung von verschiedenen Problemen.

In Unternehmen und Organisationen können die Prinzipien der Schwarmorganisation auf verschiedene Rollen und Funktionen angewendet werden, um kreativere, anpassungsfähigere und effizientere Arbeitsweisen zu fördern. Hier sind einige Beispiele für Rollen, die in einer Schwarmorganisation auftreten könnten:

1\. \*\*Koordinatoren\*\*: Diese Rolle ähnelt eher einem Katalysator als einem traditionellen Manager. Koordinatoren helfen dabei, die verschiedenen Mitglieder des Schwarmteams zu vernetzen, Informationen zu teilen und die Kommunikation zu erleichtern, um eine reibungslose Zusammenarbeit zu gewährleisten.

2\. \*\*Experten- und Wissensvermittler\*\*: Individuen, die über spezifische Kenntnisse, Fähigkeiten oder Expertise in einem Bereich verfügen, können in einer Schwarmorganisation als Ressourcen für andere Mitglieder dienen, um ihr Wissen zu teilen und die Entscheidungsfindung zu unterstützen.

3\. \*\*Innovatoren\*\*: Diese Rolle beinhaltet das Einbringen von Ideen, Konzepten und neuen Ansätzen, um die Organisation voranzubringen. Innovatoren könnten dazu beitragen, dass die Schwarmorganisation kreativ bleibt und neue Wege findet, um Herausforderungen anzugehen.

4\. \*\*Verbindungsmanager\*\*: In einer Schwarmorganisation kann es wichtig sein, Beziehungen innerhalb des Teams und mit externen Partnern aufzubauen und zu pflegen. Verbindungsmanager können die Zusammenarbeit mit anderen Organisationen, Experten oder Stakeholdern fördern.

5\. \*\*Facilitatoren\*\*: Diese Rolle konzentriert sich auf das Schaffen einer unterstützenden Umgebung, in der die Mitglieder des Schwarmteams effektiv zusammenarbeiten können. Facilitatoren könnten Workshops, Diskussionen oder andere Aktivitäten organisieren, um den Austausch von Ideen und Informationen zu fördern.

6\. \*\*Kommunikatoren\*\*: Die Fähigkeit, klare und präzise Informationen zu vermitteln, ist in einer Schwarmorganisation von entscheidender Bedeutung. Kommunikatoren helfen dabei, Missverständnisse zu minimieren und sicherzustellen, dass alle Mitglieder auf dem gleichen Stand sind.

7\. \*\*Adaptive Teammitglieder\*\*: In einer Schwarmorganisation ist es wichtig, dass alle Mitglieder flexibel und anpassungsfähig sind. Teammitglieder, die sich schnell auf neue Situationen einstellen können und bereit sind, ihre Rolle je nach Bedarf zu ändern, sind von großer Bedeutung.

8\. \*\*Ermöglicher von Feedback und Lernen\*\*: Personen, die Feedbackmechanismen etablieren und eine Kultur des Lernens fördern, sind in einer Schwarmorganisation wichtig, um kontinuierliche Verbesserungen zu ermöglichen.

Diese Rollen folgen nicht unbedingt festen Hierarchien. Stattdessen können sie je nach Situation, Projekt und Bedarf variieren. In einer Schwarmorganisation sind Rollen oft flexibel und können von den Mitgliedern je nach den Anforderungen der Aufgaben und der Gruppendynamik übernommen werden.

# DUNNING-KRUGER-EFFEKT
Der Dunning-Kruger-Effekt ist ein psychologisches Phänomen, das beschreibt, wie Menschen mit geringer Kompetenz in bestimmten Bereichen dazu neigen, ihre Fähigkeiten zu überschätzen, während gleichzeitig kompetente Personen dazu neigen, ihre Fähigkeiten zu unterschätzen. Das heißt, Menschen, die wenig Wissen oder Können in einem bestimmten Gebiet besitzen, sind oft nicht in der Lage, ihre eigene Unwissenheit zu erkennen, und fühlen sich übermäßig sicher in ihrem Wissen.

Der Effekt wurde von den Psychologen David Dunning und Justin Kruger erstmals in einer Studie aus dem Jahr 1999 beschrieben. Sie führten Experimente durch, bei denen sie die tatsächliche Leistung von Teilnehmern in verschiedenen Bereichen maßen und gleichzeitig deren Selbsteinschätzung erfragten. Dabei fanden sie heraus, dass diejenigen, die unterdurchschnittlich abschnitten, tendenziell dazu neigten, ihre Leistung zu überschätzen, während diejenigen, die überdurchschnittlich abschnitten, ihre Leistung eher unterschätzten.

Der Dunning-Kruger-Effekt kann in vielen Bereichen beobachtet werden, von akademischen Disziplinen bis hin zu alltäglichen Fähigkeiten. Menschen, die wenig Erfahrung oder Wissen haben, fehlt oft die Grundlage, um ihre eigene Inkompetenz zu erkennen, und sie sind daher anfällig für selbstüberschätzende Einschätzungen. Auf der anderen Seite können Menschen, die tatsächlich kompetent sind, dazu neigen, ihre Fähigkeiten als selbstverständlich anzusehen und deshalb nicht erkennen, wie herausragend ihre Leistungen sind.

Handelt es sich bei dem Dunning-Kruger-Effekt um ein statistisches Artefakt?

Nein, der Dunning-Kruger-Effekt ist kein statistisches Artefakt. Es handelt sich um ein psychologisches Phänomen, das in Studien und empirischen Beobachtungen wiederholt nachgewiesen wurde. Der Effekt wurde durch experimentelle Studien gestützt, in denen die tatsächliche Leistung von Personen gemessen und mit ihren Selbsteinschätzungen verglichen wurde.

Die Forschung von Dunning und Kruger sowie von anderen Wissenschaftlern hat gezeigt, dass dieser Effekt aufgrund von kognitiven Verzerrungen und Wahrnehmungsfehlern auftritt. Menschen mit geringer Kompetenz können aufgrund eines Mangels an Wissen und Verständnis nicht angemessen beurteilen, wie wenig sie tatsächlich wissen. Sie sind anfällig für das sogenannte "illusorische Überlegenheitsgefühl", bei dem sie ihre eigenen Fähigkeiten überschätzen. Gleichzeitig können kompetente Personen dazu neigen, ihre Fähigkeiten zu unterschätzen, weil sie davon ausgehen, dass das, was für sie einfach ist, auch für andere einfach sein sollte.

Der Dunning-Kruger-Effekt ist also kein statistisches Artefakt, sondern ein Phänomen, das auf psychologischen Mechanismen basiert und in verschiedenen Situationen und Kontexten beobachtet werden kann.

Frage: Wie genau wurde der Versuch von Dunning und Kruger durchgeführt?

Der Versuch von Dunning und Kruger wurde in ihrer bahnbrechenden Studie "Unskilled and Unaware of It: How Difficulties in Recognizing One's Own Incompetence Lead to Inflated Self-Assessments" aus dem Jahr 1999 durchgeführt. Hier ist eine Zusammenfassung der Grundlagen des Versuchs:

1\. \*\*Teilnehmerauswahl:\*\* Die Forscher rekrutierten Studenten, die sich freiwillig zur Teilnahme an einer Studie meldeten. Die Studienteilnehmer wurden in verschiedenen Tests auf ihre Fähigkeiten in verschiedenen Bereichen getestet. Diese Bereiche reichten von Grammatik und Logik bis hin zu Humor und emotionaler Intelligenz.

2\. \*\*Selbsteinschätzung:\*\* Nachdem die Teilnehmer die Tests abgeschlossen hatten, wurden sie gebeten, ihre eigenen Leistungen in den Tests einzuschätzen. Sie sollten ihre Erwartungen an die Ergebnisse mitteilen, wie sie im Vergleich zu anderen abschneiden würden.

3\. \*\*Vergleich der tatsächlichen Leistung mit der Selbsteinschätzung:\*\* Die tatsächlichen Testergebnisse wurden mit den Selbsteinschätzungen der Teilnehmer verglichen. Die Forscher analysierten, wie genau die Teilnehmer ihre eigenen Fähigkeiten eingeschätzt hatten, insbesondere im Vergleich zu ihren tatsächlichen Ergebnissen.

4\. \*\*Ergebnisse:\*\* Die Forscher fanden heraus, dass Personen, die in den Tests unterdurchschnittlich abschnitten, dazu neigten, ihre eigenen Leistungen zu überschätzen. Diese Personen waren sich ihrer geringen Fähigkeiten nicht bewusst und schätzten ihre Fähigkeiten als höher ein, als sie tatsächlich waren. Auf der anderen Seite neigten Personen, die überdurchschnittlich abschnitten, dazu, ihre Fähigkeiten zu unterschätzen, weil sie annahmen, dass andere genauso gut wie sie sein könnten.

Die Ergebnisse dieser Studie bestätigten den Dunning-Kruger-Effekt und legten den Grundstein für das Verständnis, wie Inkompetenz dazu führen kann, dass Menschen ihre eigenen Fähigkeiten falsch einschätzen. Die Studie wurde seitdem vielfach zitiert und hat dazu beigetragen, das Verständnis menschlicher Wahrnehmungsfehler und kognitiver Verzerrungen zu vertiefen.

Wie viele studenten nahmen an der Studie von Dunning und Kruger teil?

In der Studie von Dunning und Kruger aus dem Jahr 1999 nahmen insgesamt 65 Studenten an den Experimenten teil. 

Es ist richtig, dass es in der wissenschaftlichen Debatte unterschiedliche Ansichten über die Interpretation des Dunning-Kruger-Effekts gibt, und einige Forscher haben darauf hingewiesen, dass statistische Effekte wie die Gaußsche Verteilung eine Rolle bei der Erklärung spielen könnten. Es ist wichtig, diese Perspektiven zu betrachten, um ein vollständigeres Bild zu erhalten. Hier sind einige Aspekte, die in diesem Zusammenhang berücksichtigt werden sollten:

1\. \*\*Gaußsche Verteilung und Normalkurve:\*\* Die Gaußsche Verteilung oder Normalverteilung ist eine statistische Verteilung, die oft in der Natur auftritt und als Glockenkurve bekannt ist. Sie beschreibt, wie Werte um einen Durchschnitt herum gruppiert sind. Ein Argument in Bezug auf den Dunning-Kruger-Effekt ist, dass die meisten Menschen durchschnittlich sind, und daher würden viele Menschen in den Studien naturgemäß in den mittleren Bereich fallen, was zu einem vermeintlichen "Überschätzungseffekt" bei denjenigen führen könnte, die unterdurchschnittlich abschneiden.

2\. \*\*Kritik an der Studiendesign:\*\* Einige Kritiker des Dunning-Kruger-Effekts argumentieren, dass das Design der ursprünglichen Studien von Dunning und Kruger möglicherweise nicht ausreichend war, um andere Faktoren, die die Ergebnisse beeinflussen könnten, angemessen zu kontrollieren. Dies könnte zu einem verzerrten Bild des Effekts geführt haben.

3\. \*\*Komplexität der kognitiven Prozesse:\*\* Die Fähigkeit zur Selbstbewertung und zur Wahrnehmung von Kompetenz ist ein komplexer kognitiver Prozess. Der Dunning-Kruger-Effekt könnte das Ergebnis von verschiedenen psychologischen Mechanismen sein, darunter Verzerrungen in der Selbsteinschätzung, soziale Vergleichsprozesse und individuelle Unterschiede in der kognitiven Metakognition.

Es ist wichtig anzumerken, dass die Debatte über den Dunning-Kruger-Effekt weiterhin andauert, und es gibt keine endgültige Antwort auf die Frage, ob er vollständig auf statistische Effekte wie die Gaußsche Verteilung zurückzuführen ist oder nicht. Die Vielschichtigkeit menschlichen Verhaltens und Denkens macht es oft schwierig, einzelne Faktoren als alleinige Erklärung für ein Phänomen zu identifizieren. Forschung und wissenschaftliche Diskussionen in diesem Bereich sind daher von großer Bedeutung, um ein umfassendes Verständnis zu entwickeln.

# REGRESSION ZUM MITTELWERT
Der statistische Effekt der "Regression zur Mitte", auch als "Regression zum Mittelwert" bezeichnet, beschreibt ein Phänomen, bei dem extreme Ausreißerwerte bei wiederholten Messungen oder Beobachtungen tendenziell dazu neigen, sich in Richtung des Durchschnitts zu bewegen. Anders ausgedrückt, wenn eine erste Messung extreme Werte aufweist, wird die nächste Messung wahrscheinlich näher am Durchschnitt liegen.
# e
Das Experiment wurde von Millikan und Fletcher ab 1908/09 am Ryerson Physical Laboratory der Universität Chicago ausgeführt und 1911 und 1913 von Millikan publiziert. Der von ihnen bzw. Millikan gemessene Wert der Elementarladung war rund 0,6 Prozent niedriger als der heute akzeptierte Wert und sechsmal größer als der von Millikan selbst angegebene Standardfehler.[9] 1928 lieferten Untersuchungen mit Wellenlängenbestimmung über Röntgenstrahlbeugung an Gittern durch Erik Bäcklin[10] einen höheren Wert 

der innerhalb der Fehlergrenzen dem heutigen Wert entspricht. Weitere ähnliche Experimente und ein Elektronenbeugungsexperiment von Sten von Friesen (1937)[11] bestätigten die höheren Werte, so dass ab Ende der 1930er Jahre klar war, dass die Werte von Millikan zu niedrig waren. Nach Richard Feynman (in seinem Aufsatz zur Cargo-Kult-Wissenschaft von 1974) war die bei Wiederholungen des Öl-Tröpfchen-Experiments lange Zeit auftretenden Bestätigungen des Werts von Millikan ein Beispiel für den Einfluss großer Namen auf andere Wissenschaftler – man suchte eher bei sich nach Fehlern bei zu großen Abweichungen (bzw. suchte weniger nach Fehlern falls die eigenen Messungen gut übereinstimmten) als die Werte des Nobelpreis-gekrönten Experiments zu bezweifeln. Die Ursache für Millikan's zu niedrige Werte war wie sich 1936 herausstellte sein falscher Wert für die Viskosität der Luft.[12]

- Fazit: Stehen Sie zu Ihren Ergebnissen!

# LEAN-PHILOSOPHIE (aka LEAN-PRODUCTION)
Die Lean-Philosophie ist ein umfassender Ansatz zur Prozessoptimierung und zur Schaffung von Wertschöpfung für Kunden. Sie wurde ursprünglich im Toyota-Produktionssystem entwickelt und hat sich seitdem auf verschiedene Branchen und Bereiche ausgeweitet. Die wesentlichen Kennzeichen der Lean-Philosophie sind:

1\. \*\*Wertorientierung:\*\* Die Lean-Philosophie legt den Fokus darauf, Werte für Kunden zu schaffen. Alle Aktivitäten und Prozesse sollten darauf ausgerichtet sein, Produkte oder Dienstleistungen zu liefern, die für Kunden von Nutzen sind.

2\. \*\*Verschwendungsreduktion:\*\* Ein zentrales Prinzip des Lean-Ansatzes ist die Minderung von Verschwendung. Es werden sieben Arten von Verschwendung identifiziert: Überproduktion, Wartezeiten, Transport, Überbearbeitung, Bestände, Bewegung und Fehler. Das Ziel ist es, diese Verschwendungen zu minimieren oder zu beseitigen, um Ressourcen effizienter zu nutzen.

3\. \*\*Kontinuierliche Verbesserung:\*\* Die Lean-Philosophie betont die Notwendigkeit einer kontinuierlichen, schrittweisen Verbesserung von Prozessen, Produkten und Arbeitsmethoden. Dies geschieht durch das Einbeziehen aller Mitarbeiter, die systematisch nach Möglichkeiten zur Optimierung suchen.

4\. \*\*Kundenorientierung:\*\* Kundenbedürfnisse stehen im Mittelpunkt. Durch eine genaue Analyse der Kundenwünsche und -anforderungen wird sichergestellt, dass Produkte und Dienstleistungen den Kundenbedürfnissen entsprechen und Wertschöpfung bieten.

5\. \*\*Einbeziehung der Mitarbeiter:\*\* Lean fördert eine Kultur der Beteiligung und Einbeziehung aller Mitarbeiter. Mitarbeiter werden ermutigt, Ideen für Verbesserungen einzubringen, Probleme anzusprechen und gemeinsam nach Lösungen zu suchen.

6\. \*\*Fluss:\*\* Die Optimierung des Arbeitsflusses ist ein zentrales Anliegen. Ziel ist es, die Abfolge von Aktivitäten so zu gestalten, dass Produkte oder Dienstleistungen ohne Unterbrechungen oder Wartezeiten erstellt werden können.

7\. \*\*Pull-Prinzip:\*\* Statt auf Prognosen oder vorausschauende Planung zu vertrauen, wird das Pull-Prinzip angewendet. Das bedeutet, dass Arbeitsschritte oder Produkte nur dann in den Prozess gelangen, wenn tatsächlich Bedarf besteht, anstatt auf Vorrat zu produzieren.

8\. \*\*Standardisierung:\*\* Die Entwicklung und Anwendung von Standards für Arbeitsprozesse und Abläufe ist wichtig, um Stabilität und Qualität sicherzustellen. Standardisierung bildet die Basis für kontinuierliche Verbesserungen.

9\. \*\*Visuelle Kontrolle:\*\* Die Verwendung visueller Hilfsmittel wie Visualisierungen, Kennzahlen und Checklisten hilft dabei, den Status von Prozessen und Arbeitsabläufen auf einen Blick zu erfassen und Probleme frühzeitig zu erkennen.

10\. \*\*Respekt für Menschen:\*\* Lean betont die Wichtigkeit des Respekts für Mitarbeiter und ihre Fähigkeiten. Dies umfasst faire Behandlung, Schulung und Entwicklung sowie die Schaffung einer Arbeitsumgebung, die Mitarbeiter ermutigt, ihr Bestes zu geben.

Diese Kennzeichen bilden das grundlegende Gerüst der Lean-Philosophie. Sie wurden über Jahre hinweg entwickelt und verfeinert und können in verschiedenen Branchen und Organisationen angewendet werden, um Prozesse zu optimieren, Qualität zu steigern und Wert für Kunden zu schaffen.


Die sieben Arten der Verschwendung in der Lean-Philosophie, oft auch als "Sieben Muda" bezeichnet, sind kategorisiert als nicht-wertschöpfende Aktivitäten, die Ressourcen verschwenden und die Effizienz von Prozessen verringern. Hier sind die sieben Arten der Verschwendung und wie ihnen in der Lean-Philosophie entgegengewirkt wird:

1\. \*\*Überproduktion (Overproduction):\*\* Dies tritt auf, wenn mehr produziert wird, als tatsächlich benötigt wird, oder wenn Produkte zu früh hergestellt werden. Das führt zu unnötigem Lagerbestand, erhöhten Lagerkosten und verschwendeten Ressourcen.

`   `\*\*Entgegenwirken:\*\* Implementierung des "Pull-Prinzips", bei dem Produkte nur auf Kundenbedarf hin produziert werden, anstatt auf Vorrat. Dies reduziert die Gefahr von Überproduktion und unnötigem Lagerbestand.

2\. \*\*Wartezeiten (Waiting):\*\* Dies bezieht sich auf die Zeit, die zwischen verschiedenen Schritten eines Prozesses verloren geht, weil Arbeit in einer Phase auf die Fertigstellung einer anderen wartet.

`   `\*\*Entgegenwirken:\*\* Durch Optimierung des Arbeitsflusses, Reduzierung von Engpässen und Minimierung von Wartezeiten können Prozesse effizienter gestaltet werden.

3\. \*\*Transport (Transportation):\*\* Unnötige Bewegungen von Materialien oder Produkten zwischen verschiedenen Orten oder Abteilungen können zu Zeitverlusten, Beschädigungen und erhöhten Kosten führen.

`   `\*\*Entgegenwirken:\*\* Die physische Anordnung von Arbeitsbereichen kann optimiert werden, um unnötige Transporte zu minimieren. Lokalisierung von Materialien und Werkzeugen kann die Effizienz steigern.

4\. \*\*Überbearbeitung (Overprocessing):\*\* Dies tritt auf, wenn mehr Arbeit, Zeit oder Ressourcen in einen Prozess investiert werden, als tatsächlich erforderlich ist, um die Kundenanforderungen zu erfüllen.

`   `\*\*Entgegenwirken:\*\* Durch die Identifizierung von überflüssigen oder nicht wertschöpfenden Schritten in einem Prozess können unnötige Arbeitsschritte eliminiert oder reduziert werden.

5\. \*\*Bestände (Inventory):\*\* Hohe Lagerbestände von Rohstoffen, Zwischenprodukten oder fertigen Produkten führen zu erhöhten Lagerkosten, versteckten Qualitätsproblemen und verschwendeten Ressourcen.

`   `\*\*Entgegenwirken:\*\* Die Implementierung von Just-in-Time-Produktion (JIT) zielt darauf ab, Lagerbestände zu minimieren, indem Materialien und Produkte erst dann bereitgestellt werden, wenn sie benötigt werden.

6\. \*\*Bewegung (Motion):\*\* Unnötige Bewegungen von Mitarbeitern oder Maschinen können zu Zeitverlusten, Ermüdung und ineffizienten Arbeitsabläufen führen.

`   `\*\*Entgegenwirken:\*\* Die physische Anordnung von Arbeitsplätzen kann optimiert werden, um unnötige Bewegungen zu minimieren. Ein übersichtlicher Arbeitsplatz ermöglicht eine effizientere Arbeitsweise.

7\. \*\*Fehler (Defects):\*\* Defekte oder fehlerhafte Produkte erfordern Nacharbeit, erhöhen die Ausschussrate und führen zu Qualitätsproblemen.

`   `\*\*Entgegenwirken:\*\* Die Implementierung von Qualitätskontrollen, Fehlererkennungssystemen und kontinuierlicher Verbesserung kann dazu beitragen, die Anzahl von Fehlern zu minimieren und die Qualität zu erhöhen.

Die Lean-Philosophie strebt danach, diese Verschwendungsarten zu identifizieren und zu reduzieren, um Ressourcen besser zu nutzen, Prozesse effizienter zu gestalten und letztendlich mehr Wert für Kunden zu schaffen.
## JIT
Die Just-in-Time (JIT)-Fertigung ist eine Konzept in der Lean-Philosophie, das darauf abzielt, Materialien, Komponenten und Ressourcen genau dann bereitzustellen, wenn sie für den Produktionsprozess benötigt werden. Das Ziel der JIT-Fertigung ist es, Verschwendung zu minimieren, die Produktionskosten zu senken und die Effizienz zu steigern, indem unnötige Lagerbestände und Wartezeiten vermieden werden.

Das JIT-Konzept basiert auf mehreren Prinzipien:

1\. \*\*Bedarfsgerechte Produktion:\*\* JIT-Fertigung beruht auf der Idee, dass Produkte nur dann hergestellt werden sollten, wenn tatsächlich Bedarf von den Kunden besteht. Dies verhindert Überproduktion und hilft, Bestände zu reduzieren.

2\. \*\*Null-Lagerbestände:\*\* Das Ziel ist es, so geringe Lagerbestände wie möglich zu haben. Dies minimiert Lagerkosten, reduziert den Kapitalbedarf und verringert das Risiko von veralteten oder beschädigten Materialien.

3\. \*\*Kleine Losgrößen:\*\* Statt große Mengen eines Produkts auf einmal zu produzieren, werden kleine Losgrößen hergestellt. Dies ermöglicht eine schnellere Reaktion auf sich ändernde Kundenanforderungen und reduziert die Menge an unfertigen Produkten.

4\. \*\*Kontinuierlicher Fluss:\*\* Die Produktion wird so organisiert, dass die Materialien und Teile nahtlos von einer Phase zur nächsten übergehen, ohne längere Wartezeiten. Dies erhöht die Effizienz und reduziert Durchlaufzeiten.

5\. \*\*Flexible Produktion:\*\* JIT erfordert eine flexible Produktion, um schnell auf Änderungen in der Nachfrage reagieren zu können. Dies kann die Anpassung von Maschinen, Arbeitskräften und Produktionsprozessen umfassen.

6\. \*\*Qualitätskontrolle:\*\* Da Fehler und Qualitätsprobleme in einer JIT-Umgebung zu sofortigen Unterbrechungen führen können, wird hoher Wert auf Qualitätskontrollen und Fehlervermeidung gelegt.

JIT-Fertigung erfordert eine genaue Planung, enge Zusammenarbeit mit Lieferanten und eine sorgfältige Koordination von Produktionsprozessen. Es kann dazu beitragen, Produktionskosten zu senken, die Kapitalbindung in Lagerbeständen zu reduzieren und die Agilität eines Unternehmens zu steigern, indem es schneller auf Marktnachfrage reagiert.


##
##

